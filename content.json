{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://c89757.gitee.io/colinstar","root":"/colinstar/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-12-16T13:28:00.710Z","updated":"2021-12-16T13:28:00.710Z","comments":false,"path":"/404.html","permalink":"http://c89757.gitee.io/colinstar/404.html","excerpt":"","text":""},{"title":"分类","date":"2021-12-16T13:28:00.713Z","updated":"2021-12-16T13:28:00.713Z","comments":false,"path":"categories/index.html","permalink":"http://c89757.gitee.io/colinstar/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2021-12-16T13:28:00.712Z","updated":"2021-12-16T13:28:00.712Z","comments":false,"path":"books/index.html","permalink":"http://c89757.gitee.io/colinstar/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2021-12-16T13:28:00.712Z","updated":"2021-12-16T13:28:00.712Z","comments":false,"path":"about/index.html","permalink":"http://c89757.gitee.io/colinstar/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"Repositories","date":"2021-12-16T13:28:00.714Z","updated":"2021-12-16T13:28:00.714Z","comments":false,"path":"repository/index.html","permalink":"http://c89757.gitee.io/colinstar/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-12-16T13:28:00.713Z","updated":"2021-12-16T13:28:00.713Z","comments":true,"path":"links/index.html","permalink":"http://c89757.gitee.io/colinstar/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-12-16T13:28:00.715Z","updated":"2021-12-16T13:28:00.715Z","comments":false,"path":"tags/index.html","permalink":"http://c89757.gitee.io/colinstar/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql查看事务加锁情况","slug":"mysql查看事务加锁情况","date":"2022-11-30T14:28:17.000Z","updated":"2022-11-30T15:34:33.540Z","comments":true,"path":"2022/11/30/mysql查看事务加锁情况/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/30/mysql%E6%9F%A5%E7%9C%8B%E4%BA%8B%E5%8A%A1%E5%8A%A0%E9%94%81%E6%83%85%E5%86%B5/","excerpt":"","text":"在information_schema数据库中，有几个与事务和锁紧密相关的表。 INNODB_TRX该表存储了InnoDB存储引擎当前正在执行的事务信息，包括事务id（如果没有为该事务分配唯一的事务id，则会输出该事务对应的内存结构的指针）、事务状态（事务是正在运行还是等待获取某个锁、事务正在执行的语句等）。 例如： 在一个会话中，开启事务T1 12BEGIN;SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 然后在另一个会话中查询INNODB_TRX表 1SELECT * FROM information_schema.INNODB_TRX; trx_id：事务id trx_state：事务状态 trx_tables_locked：表示当前事务目前加了多少个表级锁； trx_rows_locked：表示该事务目前加了多少个行级锁（不包括隐式锁）； trx_lock_structs：表示当前该事务生成了多少个内存中的锁结构； INNODB_LOCKS 该表记录一些锁信息，主要包括以下两个方面。 如果一个事务想要获取某个锁但未获取到，则记录该锁信息 如果一个事务获取到了某个锁，但是这个锁阻塞了别的事务，则记录该锁信息 tips：只有当系统中发生了某个事务因为获取不到锁而被阻塞的情况时，该表中才会有记录 例如： 会话1，开启事务T1 12BEGIN;SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 会话2，开启事务T2 1SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 此时查询INNODB_LOCKS表 1SELECT * FROM information_schema.INNODB_LOCKS; 可以看到trx_id为44849和44848的两个事务被显现出来。但是无法凭借上述内容区分到底谁占用了其他事务需要的锁。 我们可以通过INNODB_LOCK_WAITS表来查看更多信息 INNODB_LOCK_WAITS该表中，表明了每个阻塞的事务是一位内获取不到哪个事务持有的锁而阻塞。接着上面的例子，查询一下该表 1SELECT * FROM information_schema.INNODB_LOCK_WAITS; 其中，requesting_trx_id表示因为获取不到锁而被阻塞的事务id; blocking_trx_id表示因为获取到别的事务的锁而导致其被阻塞的事务的事务id; tips：INNODB_LOCKS和INNODB_LOCK_WAITS这两个表在mysql5.7中被标记为过时，在mysql8.0中被移除 使用SHOW ENGINE INNODB STATUS获取锁信息 12set global innodb_status_output_locks=on; -- 可以查看到更完整的信息SHOW ENGINE INNODB STATUS; 执行该语句，得到以下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374=====================================2022-11-30 23:02:49 0x5484 INNODB MONITOR OUTPUT=====================================Per second averages calculated from the last 60 seconds-----------------BACKGROUND THREAD-----------------srv_master_thread loops: 295 srv_active, 0 srv_shutdown, 465878 srv_idlesrv_master_thread log flush and writes: 466173----------SEMAPHORES----------OS WAIT ARRAY INFO: reservation count 172OS WAIT ARRAY INFO: signal count 167RW-shared spins 0, rounds 310, OS waits 156RW-excl spins 0, rounds 397, OS waits 1RW-sx spins 0, rounds 0, OS waits 0Spin rounds per wait: 310.00 RW-shared, 397.00 RW-excl, 0.00 RW-sx------------TRANSACTIONS------------# 下一个待分配的事务id信息Trx id counter 44852 # 一些关于purge的信息Purge done for trx&#x27;s n:o &lt; 44848 undo n:o &lt; 0 state: running but idle# 每个回滚段中都有一个history链表，这些链表的总长度History list length 38# 各个事务的具体信息LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 284597729996288, not started0 lock struct(s), heap size 1136, 0 row lock(s)---TRANSACTION 284597729997160, not started0 lock struct(s), heap size 1136, 0 row lock(s)# 事务id 44851的具体信息，活跃11秒---TRANSACTION 44851, ACTIVE 11 sec starting index readmysql tables in use 1, locked 1# 该事务由2个锁结构，1个行锁LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 59, OS thread handle 52760, query id 63263 localhost ::1 root statistics# 该事务对某个库下的某个表加了IX独占意向锁TABLE LOCK table `tmp`.`single_table` trx id 44855 lock mode IXSELECT * FROM single_table WHERE id = 20 FOR UPDATE------- TRX HAS BEEN WAITING 11 SEC FOR THIS LOCK TO BE GRANTED:# 以下表示一个表结构，Space id 为290，page no 为9， n_bits属性为264 index对应的索引是primary， 锁结构中存放的所类型是X行记录锁# lock_mode X locks rec but not gap 行记录锁# lock_mode X locks gap before rec X型gap锁# lock_mode X X型next-key锁RECORD LOCKS space id 290 page no 8 n bits 264 index PRIMARY of table `tmp`.`single_table` trx id 44851 lock_mode X locks rec but not gap waiting# 记录锁Record lock, heap no 21 PHYSICAL RECORD: n_fields 10; compact format; info bits 0# hex 80000014； 主键值，20(16进制) 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000005ff4; asc _ ;; 2: len 7; hex eb000001a80110; asc ;; 3: len 5; hex 3164316136; asc 1d1a6;; 4: len 4; hex 80000014; asc ;; 5: len 5; hex 6338323337; asc c8237;; 6: len 8; hex 3664376636366161; asc 6d7f66aa;; 7: len 8; hex 6634613534376666; asc f4a547ff;; 8: len 8; hex 3566306137646365; asc 5f0a7dce;; 9: len 10; hex 33616634373037666566; asc 3af4707fef;;---------------------TRANSACTION 44848, ACTIVE 2220 sec2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 56, OS thread handle 21628, query id 63220 localhost ::1 root--------FILE I/O--------.....省略.....END OF INNODB MONITOR OUTPUT============================ SHOW ENGINE INNODB STATUS;还可以用来查看死锁 LATEST DETECTED DEADLOCK 开始的内容，即表示最近一次发生的死锁信息； 注意的是，此语句默认只会显示最近一次发生的死锁信息，可以将全局系统变量innodb_print_all_deadlocks设置为ON，这样可以将每个死锁发生时的信息都记录在Mysql的错误日志中了。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"explain详解","slug":"explain详解","date":"2022-11-15T14:35:26.000Z","updated":"2022-11-15T15:56:37.344Z","comments":true,"path":"2022/11/15/explain详解/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/15/explain%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"table该条记录代表该表的表名 id查询语句中每出现一个select关键字，mysql就会为它分配一个唯一的id; 1select * from single_table INNER JOIN single_table2 在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id值时相同的：出现在前面的表表示驱动表，出现在后面的表表示被驱动表。 对于union子句来说，会有点不同；如下 union：会把多个查询的结果集合并起来并对结果集中的记录去重。会使用临时表 所以表名是 &lt;union1,2&gt; ，即在内部创建了一个名为 &lt;union1,2&gt;的临时表；id为null表明这个临时表是为了合并两个查询的结果集而创建的。 select_typesimple查询语句中不包含UNION或者子查询的查询都算作SIMPLE类型。 primary对于包含UNION、UNION ALL或者子查询的大查询来说，它是由几个小查询组成的：其中最左边的那个查询的select_type值就是primary; union对于包含UNION或者UNION ALL的大查询来说，它是由几个小查询组成的：其中除了最左边的那个小查询以外，其余小查询的select_type值就是UNION。 union resultMysql选择使用临时表的来完成UNION查询的去重工作，针对该临时表的查询就是UNION RESULT subquery如果包含子查询的查询语句不能够被转换为对应的半连接形式，并且该子查询是不相关子查询，而且查询优化器决定采用将该子查询物化的方案来执行子查询时，该子查询的第一个select 关键字代表的那个查询的select type就是subquery 由于select type为subquery的子查询会被物化，所以该子查询只会被查询一次 dependent subquery如果包含子查询的查询语句不能够被转换为对应的半连接形式，并且该子查询被查询优化器转换为相应相关子查询的形式，则该子查询的第一个select关键字代表的那个查询的select_type就是dependent subquery。 select type为dependent subquery的子查询可能会被执行多次 dependent union在包含union或者union all的大查询中，如果各个小查询都依赖于外层查询，则除了最左边的那个小查询以外，其余小查询的select_type的值就是dependent union derived在包含派生表的查询中，如果是以物化派生表的方式执行查询，则派生表对应的子查询就的select_type就是derived; tips：在from后面的子查询称为派生表 1EXPLAIN SELECT * FROM (SELECT key1, count(*) as c FROM s1 GROUP BY key1) AS derived_s1 where c &gt; 1; id为2的记录就是代表子查询的查询方式，select_type为derived，说明该子查询是以物化的方式执行的； id为1的记录的table显示的是&lt;derived2&gt;，表示该查询是针对将派生表物化后的表进行查询的 materialized当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询。 执行计划的第三条记录的select_type值为materialized，查询优化器是将子查询先转换为物化表。 执行计划的前两条记录的id值都是1，说明这两条记录对应的表进行的是连接查询，第二条记录的table列的值是&lt;subquery2&gt;，说明该表其实就是执行计划中id为2对应的子查询物化之后产生的物化表；然后再将s1和该物化表进行连接查询， typesystem当表中只有一条记录并且该表使用的存储引擎（如Myisam、Memory）的统计数据都是精确的，那么对该表的访问方式就是system const当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方式就是const eq_ref执行连接查询时， 如果被驱动表是通过主键或者不允许存储null值的唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一不为空索引都是联合索引，则所有的索引列都必须是等值比较），则对该被驱动表的访问方式就是eq_ref ref当通过普通的二级索引列与常量进行等值匹配的方式来查询某个表时，对该表的访问方法就可能是ref 如果是连接查询，被动表中的某个普通二级索引列与驱动表中的某个列进行等值匹配，那么被驱动表也可能使用ref的访问方式 fulltxt全文检索 ref_or_null当对普通二级索引列进行等值匹配，且该索引列的值也可以是null值时 index_merge一般只会为单个索引生成扫描区间，特殊情况下可以使用索引合并 unique_subquery​ 类似于两表连接中被驱动表的eq_ref访问方法，unique_subquery是针对在一些包含IN子查询的查询语句中，如果查询优化器决定将IN子查询转换为EXISTS子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的type列的值就是unique_subquery 1EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = &#x27;a&#x27;; 会被改写成： 1select * from s1 where exists ( select 1 from s1 , s2 where s1.key2 = s2.id and s1.key1 = s2.key1) or key3 = &#x27;a&#x27; index_subquery与unique_subquey类似，只不过在访问子查询中的表时使用的是普通索引 range如果使用索引获取某些范围区间的记录，那么就可能使用到range访问方法，比如下边的这个查询： 1SELECT * FROM s1 WHERE key1 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;); index当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是index 1SELECT key_part2 FROM s1 WHERE key_part3 = &#x27;a&#x27;; 上述查询中的搜索列表中只有key_part2一个列，而且搜索条件中也只有key_part3一个列，这两个列又恰好包含在idx_key_part这个联合索引中，可是搜索条件key_part3不能直接使用该索引进行ref或者range方式的访问，只能扫描整个idx_key_part索引的记录，所以查询计划的type列的值就是index。 另外，对于Innodb来说，当我们需要执行全表扫描，并且需要对主键排序时，此时的type列也是index all全表扫描 possible_keys 与 keypossible_keys：对某个表执行单表查询可能使用到的索引有哪些 key：表示实际用到的索引有哪些 tips：possible_keys列的值并不是越多越好，可以使用的索引越多，查询优化器在计算查询成本时花费的时间也越长 在使用index访问方式查询某个表时，possible_keys列时空的，而key列展示实际用到的索引 key_len","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"Mysql子查询","slug":"Mysql子查询","date":"2022-11-13T10:07:59.000Z","updated":"2022-11-13T14:34:16.039Z","comments":true,"path":"2022/11/13/Mysql子查询/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/13/Mysql%E5%AD%90%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"子查询的分类按照出现位置区分1、在select子句中 如： 1select (select m1 from t1 limit 1); 2、在From子句中 如： 1select m,n from (select m2 as m , n2 as n from t2 where m &gt; 2 ) as t ; 3、在where或on子句的表达式中 如： 1select * from t1 where m1 in ( select m2 from t2 ); 按返回的结果集区分 标量子查询 只返回一个单一列值的子查询 比如： 1select * from t1 where m1 = ( select MIN(m2) from t2); 行子查询 返回一条记录的（一行的）子查询。不过这条记录需要包含多个列（如果只包含一个列，就是标量子查询） 如： 1select * from t1 where (m1 ,n1) = (select m2 ,n2 from t2 limit 1); 列子查询 查询出一个列的数据，不过这一列包含很多（其他行的）数据 如： 1select * from t1 where m1 in (select m2 from t2); 表子查询 即子查询的结果既包含很多条记录，又包含很多个列 如： 1select * from t1 where (m1,n1) in ( select m2 , n2 from t2); 按与外层查询的关系来区分 不相关子查询 子查询可以单独运行出结果，不依赖于外层查询的值 相关子查询 子查询的执行需要依赖于外层查询的值 如： 1select * from t1 where m1 in (select m2 from t2 where n1 = n2); 子查询的执行过程标量子查询、行子查询的执行过程不相关查询如： 1select * from s1 where key1 = (select common_field from s2 where key3 = &#x27;a&#x27; limit 1); 1、先单独执行子查询 2、然后将子查询得到的结果作为外层查询的参数，再执行外层的 select * from s1 where key1 = xxx 相关查询如： 1select * from s1 where key1 = (select common_field from s2 where s1.key3 = s2.key3 limit 1) 1、先从外层查询获取一条记录。即先从s1表中获取一条记录 2、然后从这条记录中找出子查询涉及的列。即key3 ，然后执行子查询 3、根据子查询的查询结果，来检测是否与外层查询的where条件相符合。如果条件成立符合，加入结果集。反之丢弃 4、跳到步骤1，重复此过程，直到外层查询获取不到记录为止 IN子查询的优化 例如： 1select * from s1 where key1 in (select common_field from s2 where key3 = &#x27;a&#x27;); 我们是否可以将子查询转换为连接呢？ 1select s1.* from s1 inner join s2 on s1.key1 = s2.common_field where s2.key3 = &#x27;a&#x27;; 其实效果是很像的，但是区别在于，我们并不知道子查询的结果有多少条。如果有多条，那查询出来的结果可能会重复加入结果集 我们可以分为三种情况讨论 1、对于s1表中的某条记录来说，s2表中没有任何记录满足s1.key1 = s2.common_field，那么该结果不会加入结果集 2、对于s1表中的某条记录来说，s2表中有且只有一条记录满足s1.key1 = s2.common_field，那么该结果会被加入结果集 3、对于s1表中的某条记录来说，s2表中至少有两条记录满足s1.key1 = s2.common_field，那么该结果会被多次加入最终的结果集 对于s1表中的某条记录来说，我们只关心s2表中是否存在记满足key1 = s2.common_field条件，并不关心具体有多少条记录与之匹配； 半连接(semi-join)：将s1表和s2表进行半连接的意思就是，对于s1表中的某条记录来说，我们只关心在s2表中是否存在与之匹配的记录，而不关心具体有多少条记录匹配，最终的结果集中只保留s1表中的记录。 Table pullout（子查询中的表上拉）当子查询的查询列表处只有主键或者唯一索引列时，可以直接把子查询中的表上拉到外层查询的from子句中，并把子查询中的搜索条件合并到外层查询的搜索条件中。 如： 1select * from s1 where key2 in (select key2 from s2 where key3 = &#x27;a&#x27;); key2是唯一二级索引列，我们可以直接进行table pullout。上拉后的查询就是下面这样 1select s1.* from s1 inner join s2 on s1.key2 = s2.key2 where s2.key3 = &#x27;a&#x27;; Duplicate Weedout（重复值消除）如： 1select * from s1 where key1 in ( select common_field from s2 where key3 = &#x27;a&#x27; ) 在转换为半连接查询后，s1表中的某条记录可能在s2表中有多条匹配的记录，所以该条记录可能多次被添加到最后的结果集中。 我们可以建立一个临时表，比如这个临时表如下所示： 123CREATE TABLE tmp ( id int primary key ); 这样在执行连接查询的过程中，每当某条s1表中的记录要加入到结果集时，就首先把这条记录的id值加入到这个临时表中。 如果添加成功，则说明之前这条s1表中的记录并没有加入最终的结果集，现在把该记录添加到最终的结果集；如果添加失败，则说明这条s1表中的记录之前已经加入到最终的结果集。这种使用临时表消除半连接结果集中重复值的方式Duplicate Weebout。 LooseScan（松散扫描）1select * from s1 where key3 in ( select key1 from s2 where key1 &gt; &#x27;a&#x27; and key1 &lt; &#x27;d&#x27;); 在子查询中，对于s2表的访问可以使用到key1列的索引，而子查询的查询列表处恰好就是在key1列。 可以将子查询后的s2作为驱动表，然后从查询出来的结果集中，只取键值相同的第一条记录去执行匹配操作 Semi-join Materialization (半连接物化)如不相关的in子查询 1select * from s1 where key1 in (select common_field from s2 where key3 = &#x27;a&#x27; ); 对于不相关的in子查询来说，如果子查询结果集中的记录条数很少，那么把子查询和外层查询分别看成两个单独的单表查询，效率还是蛮高的，但是，如果单独执行子查询后的结果集太多，就会导致结果集太多，可能内存都放不下。 于是mysql不直接将不相关子查询的结果集当作外层查询的参数，而是将该结果写入一个临时表中。 该临时表的列就是子查询结果集中的列 写入临时表的记录会被去重 一般情况下，子查询结果集不会太大，所以会为它建立基于内存的使用MEMORY存储引擎的临时表，而且还会为该表建立哈希索引。 （IN语句的本质就是判断某个操作数是否存在于某个集合中，建立哈希索引，判断匹配的过程会非常快） 如果子查询的结果集非常大，超过了系统变量tmp_table_size或者max_heap_table_size的值，临时表会转而使用基于磁盘的存储引擎来保存结果集中的记录，索引类型也相应地转换为B+树索引 将子查询结果集中的记录保存到临时表的过程称为物化（materialize) 当我们把上述sql的子查询物化后，假设物化后的表名称为materialize_table，该物化表存储的子查询结果集的列为m_val。那么这个子查询就相当于 1select s1.* from s1 inner join materialize_table on key1 = m_val; 因为物化表中没有重复的记录，所以可以直接将子查询转换为连接查询。 （针对不相关子查询，相关子查询并不是一个独立的查询，不能转换为物化表） FirstMatch(首次匹配)先取一条外层查询中的记录，然后到子查询的表中寻找符合匹配条件的记录。如果能找到一条，则将该外层查询的记录放入最终的结果集，并且停止查找更多匹配的记录。如果找不到，则把该外层查询的记录丢弃掉。然后取下一条外层查询中的记录。不断重复此过程，直到外层查询获取不到记录为止。 半连接适用条件并不是所有的IN子查询的查询语句都可以转换为半连接 1、该子查询必须是与IN操作符组成的布尔表达式，并且在外层的where 或者 on 子句中出现 2、外层查询也可以有其他的搜索条件，只不过必须使用AND操作符与IN子查询的搜索条件 3、该子查询必须是一个单一的查询，不能是由UNION连接起来的若干查询 4、该子查询不能包含GROUP BY 、HAVING语句或者聚合函数 不适用于半连接的情况 1、在外层查询的WHERE子句中，存在其他搜索条件使用OR操作符与IN子查询组成的布尔表达式连接起来的情况 2、使用NOT IN 而不是IN 3、位于select子句中的IN子查询 4、子查询包含GROUP BY 、HAVING语句或者聚合函数 5、子查询中包含UNION的情况 但是，mysql仍然可以优化不能转为半连接查询的子查询。 对于不相关的子查询，可以尝试把它们物化之后再参与查询 如： 1select * from s1 where key1 not in (select common_field from s2 where key3 = &#x27;a&#x27;) 先将子查询物化，然后再判断key1是否在物化表中的结果集中。这样可以加快查询的执行速度 注意：这里子查询物化之后，不能转为与外层表连接查询。 无论子查询是相关的还是不相关的，都可以把IN子查询尝试转为EXISTS子查询 outer_expr IN (select inner_expr from … where subquery_where) 可以被转换为： EXISTS （select inner_expr from …. where subquery_where AND outer_expr=inner_expr) 某些情况，不转换的话可能用不到索引。 如果IN子查询符合转换半连接的条件，查询优化器会优先把该子查询转换为半连接，然后再考虑上述五种半连接的策略中，选取成本最低的策略来执行子查询 如果IN子查询不符合转换为半连接的条件，那么查询优化器会从下面两种策略中找出一种成本最低的方式来执行子查询。 先将子查询物化，再执行查询 执行IN到EXISTS的转化 [NOT] EXISTS子查询的执行如果[NOT] EXISTS子查询是不相关子查询。可以先执行子查询，得出该子查询的结果是true还是false，然后重写原先的查询语句 如： 1select * from s1 where exists (select 1 from s2 where key1 = &#x27;a&#x27;) or key2 &gt; 100; 因为该子查询是不相关子查询，所以查询优化器会首先执行该子查询。最后查询优化器会重写查询： 1select * from s1 where TRUE|FALSE or key2 &gt; 100 对于相关的[NOT] EXISTS子查询来说，如： 1select * from s1 where exists (select 1 from s2 where s1.common_field = s2.common_field) 那么只能最原始的执行方式来执行。先从外层取一条数据，然后作为内层查询的参数，判断条件是否匹配。 不过我们可以使用索引，加快查询速度。如给s2.common_field加上索引 派生表的优化把子查询放在外层查询的FROM子句后，这个子查询相当于一个派生表。 对于含有派生表的查询，Mysql提供了两种执行策略 把派生表物化 我们可以将派生表的结果集写到一个内部的临时表中，然后把这个物化表当作普通表一样来参与查询。 再对派生表物化时，mysql使用了一种称为延迟物化的策略，也就是查询过程中，真正使用到派生表时，才会去尝试物化派生表，而不是查询之前就先把派生表物化。 1select * from (select * from s1 where key1 = &#x27;a&#x27; ) as drived_s1 inner join s2 on drived_s1.key1 = s2.key1 where s2.key2 = 1; 如果采用物化表的方式执行这个查询，在执行时首先会到s2表中找出满足s2.key2=1的记录，如果压根儿找不到，说明参与连接的s2表记录为空，结果集为空，没必要去物化表了。 将派生表和外层查询合并 即：将查询重写为没有派生表的形式 1select * from (select * from s1 where key1 = &#x27;a&#x27; ) as drived_s1 inner join s2 on drived_s1.key1 = s2.key1 where s2.key2 = 1; 我们可以将派生表与外层查询合并 1select * from s1 inner join s2 on s1.key1 = s2.key1 where s1.key1 = &#x27;a&#x27; where s2.key2 = 1; 这样改写后，成功的消除了派生表，也就意味着我们没必要付出创建和访问临时表的成本了。 并不是所有带有派生表的查询都能成功的与外层查询合并。当派生表中有下面这些函数或语句时，就不可以与外层查询合并 聚合函数，比如MAX()，MIN()，SUM()等 DISTINCT GROUP BY HAVING LIMIT UNION 或者 UNION ALL 派生表对应的子查询的select 子句中含有另一个子查询 …… 所以，mysql在执行带有派生表的查询时，会优先尝试把派生表和外层查询进行合并；如果不行，再采用物化表执行查询","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"查询的成本","slug":"查询的成本","date":"2022-11-07T15:15:38.000Z","updated":"2022-11-07T16:29:33.673Z","comments":true,"path":"2022/11/07/查询的成本/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/07/%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%88%90%E6%9C%AC/","excerpt":"","text":"单表查询的成本概述IO成本：我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引都存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。 CPU成本：读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。 对于InnoDB来说，页是磁盘和内存之间进行交互的基本单位。Mysql规定，读取一个页面花费的成本默认是1.0；读取以及检测一条记录是否符合搜索条件的成本默认是0.2。 tips：在读取记录时，即使不需要检测记录是否符合搜索条件，其成本也算作0.2 准备工作 123456789101112131415CREATE TABLE single_table ( id int NOT NULL auto_increment, key1 VARCHAR ( 100 ), key2 INT, key3 VARCHAR ( 100 ), key_part1 VARCHAR ( 100 ), key_part2 VARCHAR ( 100 ), key_part3 VARCHAR ( 100 ), common_field VARCHAR ( 100 ), PRIMARY KEY ( id ), KEY idx_key1 ( key1 ), UNIQUE KEY uk_key2 ( key2 ), KEY idx_ke3 ( key3 ),KEY idx_key_part ( key_part1, key_part2, key_part3 ) ) ENGINE = INNODB CHARSET = utf8; 存储过程脚本插入1w数据 12345678910111213141516CREATE DEFINER=`root`@`localhost` PROCEDURE `genData`()begin DECLARE n INT DEFAULT 1; WHILE n &lt;= 10000 DO insert into single_table(key1,key2,key3,key_part1,key_part2,key_part3,common_field) values( substring(md5(rand()), 1, 5), n, substring(md5(rand()), 1, 5), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 10)); SET n = n + 1; END WHILE;end 基于成本的优化步骤​ 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的执行计划，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 如下面的查询语句： 12345678910SELECT * FROM single_table WHERE key1 IN ( &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27; ) AND key2 &gt; 10 AND key2 &lt; 1000 AND key3 &gt; key2 AND key_part1 LIKE &#x27;%hello%&#x27; AND common_field = &#x27;123&#x27;; 1、根据搜索条件，找出所有可能使用的索引​ 很显然，上面的查询语句，可能用到的索引有 idx_key1( key1) 、uk_key2(key2) 2、计算全表扫描的代价​ 全表扫描即：把聚簇索引中的记录都依次与给定的搜索条件进行比较，并把符合条件的记录加入结果集中。所以需要将聚簇索引对应的页面加载到内存中，然后再检测记录是否符合搜索条件。 ​ 由于查询成本 = I/O成本 + CPU成本。所以计算全表扫描的代价需要两个信息： 聚簇索引占用的页面数 该表中的记录数 Mysql为每个表维护了一系列的统计信息。我们可以通过如下sql进行查询 1SHOW TABLE STATUS LIKE &#x27;single_table&#x27; 结果大致如下： 其中： Rows：表示表中记录条数。对于Myisam存储引擎来说，该值是准确的；对于Innodb来说，该值是估计值 Data_length：表示表占用的存储空间字节数。对于Myisam来说，该值就是数据文件的大小；对于Innodb引擎来说，该值就相当于聚簇索引占用的存储空间大小。 对于Innodb的存储引擎来说，Data_length = 聚簇索引的页面数量 * 每个页面大小 由于默认页面大小为16kb，上面查询出来的Data_length = 1589248，所以可以求出聚簇索引的页面数量 ​ 聚簇索引的页面数量 = 1589248 / 16 / 1024 = 97 所以I/O成本 = 97 * 1.0 = 97 （97页，每页成本1.0） CPU成本 = 9317 * 0.2 = 1863.4 （Rows = 9317行，每行检索成本0.2） 总成本 = 97 + 1863.4 = 1960.4 所以对该表的全表扫描成本即为 1960.4 3、计算使用不同索引执行查询的代价Mysql查询优化器会优先分析使用唯一二级索引的成本，再分析普通索引的成本。所以先分析uk_key2的成本 uk_key2的对应的搜索条件为 key2 &gt; 10 and key2 &lt; 1000，即对应扫描区间为（10，1000） 扫描区间数量 无论某个扫描区间的二级索引到底占用了多少页面，查询优化器粗暴的认为读取索引的一个扫描区间的I/O成本与读取一个页面的I/O成本相同； 此处的扫描区间数量只有一个: （10，1000），所以加载页面的I/O成本为1.0 需要回表的记录数 查询优化器需要先计算二级索引的某个扫描区间到底包含多少记录，对于本例来说，就是计算uk_key2在扫描区间（10，1000）中包含多少二级索引记录。 计算过程如下： 1、先根据key2 &gt; 10条件访问uk_key2对应的B+树索引，找到满足key2 &gt; 10 的第一条记录，称为最左记录。（此过程性能消耗可以忽略不计） 2、然后再根据key2 &lt; 1000条件访问uk_key2对应的B+树索引，找到最后一条满足key2 &lt; 1000的记录，称为最右记录。 3、如果最左记录和最右记录相隔不太远（Mysql5.7.22版本中，只要不大于10个页面即可），就可以精确统计出满足key2 &gt; 10 and key2 &lt; 1000条件的二级索引记录条数 tips：数据页中有个Page Header部分。Page Header中有一个PAGE_N_RECS属性，记录了该页面中目前有多少条记录。所以如果最左记录和最右记录相隔不太远，直接遍历这些页面，拿到这个属性相加即可 如果最左记录和最右记录相隔比较远，则沿着最左记录向右读10个页面，计算每个页面平均包含多少记录，然后用这个平均值乘以最左记录和最右记录之前的页面数量即可。 假设根据上述方法，测得uk_key2再区间（10，1000）中大约有95条记录。读取这95条二级索引记录需要付出的CPU成本为 95 * 0.2 = 19 根据这些记录的主键值到聚簇索引中执行回表操作 Mysql在评估回标操作的I/O成本时，粗暴的认为每次回表操作都相当于访问一个页面； 所以I/O成本就是 95 * 1.0 = 95 回表得到完整记录后，再检测其他搜索条件是否成立 我们通过扫描区间获取到的二级索引记录有95条，对应着聚簇索引中的95条完整用户记录。读取并检测这些完整的用户记录是否符合其余的搜索条件，所以CPU成本为：95 * 0.2 = 19 所以综上所述，使用uk_key2执行查询的总成本为：1.0 + 95 * 0.2 + 95 * 1.0 + 95 * 0.2 = 134 使用普通二级索引执行查询的成本略 基于索引统计数据的成本计算有时候，在使用索引执行查询时，会有很多个单点扫描区间，比如in语句： 1select * from single_table where key1 in (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27; , .... &#x27;zzz&#x27;); 很显然这个查询语句可能使用到的索引就是idx_key1。由于这个索引并不是唯一二级索引，所以并不能确定一个单点扫描区间内对应的二级索引记录的条数有多少（唯一二级索引不重复，所以有多少个in就有多少个等值比较；但普通索引，一个in值里可能包含许多重复的值）。所以我们要去计算一下，计算方式就是先获取索引对应的B+树的区间最左记录和最右记录，然后再计算这两条记录之间有多少记录。 这种通过直接访问索引对应的B+树来计算某个扫面区间内对应的索引记录条数的方式称为**index dive** 如果只是零星几个单点扫描区间的话，使用index dive来计算这些单点扫描区间对应的记录数没什么问题。但是当扫描区间很多时，使用这种方法带来的性能损耗太大了，可能计算这些扫描区间对应的索引记录条数的成本比直接全表扫描的成本都大。 mysql中提供了一个系统变量eq_range_index_limit 1SHOW VARIABLES LIKE &#x27;%dive%&#x27; 也就是说，如果in语句生成的单点扫描区间的数量小于200个，将使用index dive来计算各个单点扫描区间对应的记录条数。 如果大于等于200个，将使用索引统计数据（index statistics）来进行估算。具体如何估算如下： Mysql会为表中每个索引维护一份统计数据。可以通过如下sql查看 1show index from single_table; Non_uniqe：该列所属索引是否是唯一索引。 Seq_in_index：该列在索引包含的列中位置。对于联合索引idx_key_part来说，key_part1的位置是1，key_part2的位置是2 Cardinality：该列中不重复值的数量。（是一个估算值，并不精确）比如对于一个有10000行记录的表来说，如果Cardinality = 10000，表明表中没有重复的值；如果Cardinality = 1，表示该列的值全部都是重复值； 索引统计数据（index statistics) 1、使用show table status语句显示出来的rows值，表示表中有多少记录 2、使用show index from语句显示出来的Cardinality值， 我们可以计算出，某一个列中一个值平均重复多少次。即 rows / Cardinality 假设Rows值为9693，key1列Cardinality值为968，计算出来单个列的平均重复次数为：9693 / 968 ≈ 10条 假设in语句包含着2000个单点扫描区间。每个扫描区间大约对应10条记录。所以总共需要回表的成本就是 2000 * 10 * 1.0 tips：索引统计数据致命弱点是不准确！算出来的查询成本与实际执行时的成本可能相差较大。如果eq_range_index_limit值太小，则很容易采用索引统计数据来计算查询成本，可能导致计算出来的查询成本太大而导致不走索引。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"}]},{"title":"表空间","slug":"表空间","date":"2022-11-05T05:29:02.000Z","updated":"2022-11-05T05:40:51.456Z","comments":true,"path":"2022/11/05/表空间/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/05/%E8%A1%A8%E7%A9%BA%E9%97%B4/","excerpt":"","text":"","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"}]},{"title":"Springboot自动装配","slug":"Springboot自动装配","date":"2022-06-18T14:23:15.000Z","updated":"2022-06-19T11:14:26.761Z","comments":true,"path":"2022/06/18/Springboot自动装配/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/18/Springboot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/","excerpt":"","text":"​ 启动Springboot代码很简单，直接一行代码SpringApplication.run(class,args)搞定，其实这一步可以拆解成两步，SpringApplication.run方法里面，其实也是先new SpringApplication，然后调用它的run方法 12345678@SpringBootApplicationpublic class TestApplication &#123; public static void main(String[] args) &#123; // SpringApplication.run(TestApplication.class,args); SpringApplication springApplication = new SpringApplication(TestApplication.class); springApplication.run(args); &#125;&#125; new SpringApplication() 123public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources);&#125; 1234567891011121314public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); // 1、将启动类存入primarySources中 this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 2、根据classpath下的类，推算当前web应用类型（webFlux,servlet) this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 3、去spring.factoryies中获取所有key为`org.springframework.context.ApplicationContextInitializer`的值 ,设置容器的初始化器 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 4、同3获取所有key为`org.springframework.context.ApplicationListener`的值,设置容器的监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 5、根据调用栈推断出main方法所在类，获取其class对象 this.mainApplicationClass = deduceMainApplicationClass();&#125; setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); 123private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;);&#125; 调用重载方法 1234567private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 先看SpringFactoriesLoader.loadFactoryNames(type, classLoader)这个方法 1234public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return (List)loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());&#125; 这里又可以分为两步，先是loadSpringFactories(classLoader) 12345678910111213141516171819202122232425262728293031323334353637// 静态常量cache，用于缓存private static final Map&lt;ClassLoader, MultiValueMap&lt;String, String&gt;&gt; cache = new ConcurrentReferenceHashMap(); private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; // 先从缓存中取 MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; // 获取资源定位 Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;)); result = new LinkedMultiValueMap&lt;&gt;(); // 遍历元素，添加到集合中 while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryTypeName, factoryImplementationName.trim()); &#125; &#125; &#125; // 以classloader为key,放入cache cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; &#125; ​ ​ 就是加载类路径下中所有的spring.factories，把他们放入一个map中，然后getOrDefault(factoryTypeName, Collections.emptyList()); 获取以org.springframework.context.ApplicationContextInitializer为key的所有值.然后放入Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(..）中 ​ 紧接着是这一行 List instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); 12345678910111213141516private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex); &#125; &#125; return instances;&#125; 循环遍历刚刚拿到的集合，然后反射去创建实例 applcaiton.run(args)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public ConfigurableApplicationContext run(String... args) &#123; // stopwatch记录开始 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //1、 获取org.springframework.boot.SpringApplicationRunListener监听器 SpringApplicationRunListeners listeners = getRunListeners(args); // 事件ApplicationStartingEvent发布 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 2、读取配置文件appcaiton.yml... ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 打印banner Banner printedBanner = printBanner(environment); // 3、创建spring上下文 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 4、初始化上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 5、refresh方法 refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 1、 获取SpringApplicationRunListener监听器与事件发布*123456private SpringApplicationRunListeners getRunListeners(String[] args) &#123; // 有参构造方法所需参数 Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125; 1.1 getSpringFactoriesInstances getSpringFactoriesInstances就是new SpringApplication()里面所看到的，这次会从缓存cache中直接获取key为org.springframework.boot.SpringApplicationRunListeners所有的值，并反射创建其实例。 1234567private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 默认有一个 org.springframework.boot.context.event.EventPublishingRunListener；在Springboot的官方包里有配置 值得注意的是，在反射创建SpringApplicationRunListeners实例时，会调用其有参构造方法，将application，和args传入 12345678910111213public EventPublishingRunListener(SpringApplication application, String[] args) &#123; this.application = application; this.args = args; // 创建事件多播器 this.initialMulticaster = new SimpleApplicationEventMulticaster(); for (ApplicationListener&lt;?&gt; listener : application.getListeners()) &#123; // 将监听器添加到事件多播器中 this.initialMulticaster.addApplicationListener(listener); &#125;&#125;// 注意此处 application.getListeners()中，其值就是在new Applicaiton()中添加的；代码如下一行所示setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); 1.2 new SpringApplicationRunListeners() 再看看new SpringApplicationRunListeners()；构造器里只是做了赋值；将反射创建的实例EventPublishingRunListener赋值进去 1234SpringApplicationRunListeners(Log log, Collection&lt;? extends SpringApplicationRunListener&gt; listeners) &#123; this.log = log; this.listeners = new ArrayList&lt;&gt;(listeners);&#125; 1.3 listeners.starting() 调用SpringApplicationRunListeners的starting方法,里面就是循环listeners，然后调用其实现的starting()方法；此时此处的listeners里面就一个刚刚反射创建的EventPublishingRunListener。又会去调用它的starting方法 12345void starting() &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.starting(); &#125;&#125; EventPublishingRunListener.starting(); 123456@Overridepublic void starting() &#123; // initialMulticaster多播器里面，装的都是初始化SpringApplicaiton时，从Spring.factories中加载、并反射创建的实例 // 注意此处的是将类型为:ApplicationStartingEvent this.initialMulticaster.multicastEvent(new ApplicationStartingEvent(this.application, this.args));&#125; multicastEvent方法会去调用实现了ApplicationListener&lt;ApplicationStartingEvent&gt;的实现类；(一开始会发布一个ApplicationStartingEvent事件) 12345678910111213141516171819@Overridepublic void multicastEvent(ApplicationEvent event) &#123; multicastEvent(event, resolveDefaultEventType(event));&#125;@Overridepublic void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); // getApplicationListeners(event, type)获取对应事件类型的listeners for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125;&#125; 2、读取配置文件ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); 123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); // 发布ApplicationEnvironmentPreparedEvent事件 listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; springboot里面配置文件的加载，也是通过事件监听器完成的，此处会发布ApplicationEnvironmentPreparedEvent事件，在ConfigFileApplicationListener 类中。会去完成配置文件的加载 public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered 3、创建上下文context = createApplicationContext(); 1234567891011121314151617181920212223protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: // 根据web类型，如果是SERVLET，创建AnnotationConfigServletWebServerApplicationContext contextClass = Class.forName(&quot;org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext&quot;); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( &quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; AnnotationConfigServletWebServerApplicationContext继承自ServletWebServerApplicationContext 4、初始化上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); 123456789101112131415161718192021222324252627282930private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); // 读取配置类 load(context, sources.toArray(new Object[0])); // 发布ConfigurableApplicationContext事件 listeners.contextLoaded(context);&#125; 123456789101112131415161718private int load(Class&lt;?&gt; source) &#123; if (isGroovyPresent() &amp;&amp; GroovyBeanDefinitionSource.class.isAssignableFrom(source)) &#123; // Any GroovyLoaders added in beans&#123;&#125; DSL can contribute beans here GroovyBeanDefinitionSource loader = BeanUtils.instantiateClass(source, GroovyBeanDefinitionSource.class); load(loader); &#125; if (isEligible(source)) &#123; this.annotatedReader.register(source); return 1; &#125; return 0;&#125;public void register(Class&lt;?&gt;... componentClasses) &#123; for (Class&lt;?&gt; componentClass : componentClasses) &#123; registerBean(componentClass); &#125;&#125; 5、refresh refreshContext(context); 123protected void refresh(ConfigurableApplicationContext applicationContext) &#123; applicationContext.refresh();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // 解析配置类，@Bean/@Import/@ImportSource/@ComponentScan等;将他们创建成beanDefinition invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // 这里会去创建内嵌tomcat onRefresh(); // Check for listener beans and register them. registerListeners(); // 初始化bean finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 相关注解@Import通过@Import( {类名.class,类名.classs…} )，直接导入某个类的方式，将类加入到spring的IOC容器中 ImportSelector @Import({类名.class})，其中类实现ImportSelector接口，重写selectImports方法，返回值就是要导入bean的全类名 参数AnnotationMetadata 就是被import注解的类的所有注解信息 1234567891011121314151617181920@Component@Import(User.class)public class Test &#123;&#125;public class User implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; Set&lt;String&gt; annotationTypes = annotationMetadata.getAnnotationTypes(); for (String annotationType : annotationTypes) &#123; System.out.println(&quot;---&gt;&quot;+ annotationType); &#125; // 打印内容 // ---&gt;org.springframework.stereotype.Component // ---&gt;org.springframework.context.annotation.Import return new String[]&#123;&quot;com.example.Colin&quot;&#125;; &#125;&#125; ImportBeanDefinitionRegistrar 自定义类实现ImportBeanDefinitionRegistrar接口，重写其registerBeanDefinitions方法；最后通过@Import将这个类导入进来 @EnableAutoConfigurationspringboot启动类上通常会加上@SpringBootApplicaiton注解，而在此注解上又有@EnableAutoConfiguration 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration 可以看到里面有用到@Import导入了AutoConfigurationImportSelector类，其实现了DeferredImportSelector接口；继承该接口的 ImportSelector会在所有@Configuration配置类处理完后运行 DeferredImportSelector继承了ImportSelector，AutoConfigurationImportSelector重写了selectImports方法 并且！还重写了DeferredImportSelector中的getImportGroup方法.springboot加载的时候会去判断，如果重写了此方法，返回一个class，就会去调用class对饮的process方法，在这个方法里，会去分组，主要为了保证加载的顺序 1234@Overridepublic Class&lt;? extends Group&gt; getImportGroup() &#123; return AutoConfigurationGroup.class;&#125; 12345678910111213@Overridepublic void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector, () -&gt; String.format(&quot;Only %s implementations are supported, got %s&quot;, AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector) .getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125;&#125; 内嵌tomcat导入tomcat依赖，然后可以通过如下代码创建tomcat，并可以添加servlet 1234567891011121314151617181920212223public class TestTomcat &#123; private static final String contextPath = &quot;&quot;; public static void main(String[] args) &#123; Tomcat tomcat = new Tomcat(); tomcat.setPort(8099); String baseDir = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath(); try &#123; Context context = tomcat.addContext(contextPath, baseDir); context.addServletContainerInitializer( (c,servletContext) -&gt; &#123; ServletRegistration.Dynamic testServlet = servletContext.addServlet(&quot;testServlet&quot;, new TestServlet()); testServlet.addMapping(&quot;/hello&quot;); &#125;,null); tomcat.start(); &#125; catch (LifecycleException e) &#123; e.printStackTrace(); &#125; tomcat.getServer().await(); &#125;&#125;","categories":[{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/tags/springboot/"}]},{"title":"maven打包报错:Malformed \\uxxx encoding","slug":"maven打包报错-Malformed-uxxx-encoding","date":"2022-06-09T14:27:51.000Z","updated":"2022-06-09T15:16:01.862Z","comments":true,"path":"2022/06/09/maven打包报错-Malformed-uxxx-encoding/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/09/maven%E6%89%93%E5%8C%85%E6%8A%A5%E9%94%99-Malformed-uxxx-encoding/","excerpt":"","text":"​ 在最近一次项目构建中，执行mvn clean package却报出Malformed \\uxxx encoding的错误。查阅资料后，给出了以下几种解决方式： 删除~/.m2/repository/path-to-the-library的包 将项目中的/更改为\\ 对我来说都不得行，最后查阅到有人说是resolver-status.properties损坏，里面包含了\\u0000， 然后我就根据Maven提示，带上参数 -e - X 执行命令：Maven -e - X clean package，日志打印出是哪个包报错， 最后来到仓库中，删除对应的resolver-status.properties文件，再次构建成功！ 那resolver-status.properties文件是干嘛的呢？ Maven更新本地仓库的步骤是：先更新元文件，再根据元文件去更新本地仓库jar包 而元文件有三个maven-metadata-local.xml，maven-metadata-snapshot-nexus.xml，resolver-status.properties maven-metadata-local.xml 在本地install代码后会生成该文件，记录的是本地项目编译的时间戳 maven-metadata-snapshot-nexus.xml 从远程仓库拉取jar包后，会同时从仓库下载该元文件，该文件记录的是远程仓库上项目最新版本的时间 resolver-status.properties 从远程仓库拉取jar包的时候，也会生成该文件，并且每次拉取都会更新。该文件主要作用是记录maven-metadata–nexus.xml 文件的上次更新时间戳，并结合标签完成更新策略的一部分 更新本地jar包：依赖于 maven-metadata-local.xml 和 maven-metadata-snapshot-nexus.xml 两个文件 如果只有 maven-metadata-local.xml 文件，一般来说是配置有错，或者并没有从远程仓库中拉取过jar包 如果两个文件都有，每次都需要比较一下两个文件的时间戳，即标签上的时间戳。 如果local.xml的时间戳比snapshot.xml的时间戳要新，就不会从远程仓库下载； 如果local.xml的时间戳比snapshot.xml的时间戳要旧，就会去检查一下本地maven仓库的该项目文件夹路径下是否有snapshot.xml对应版本的jar包 如果没有该版本的jar包，就会从远程仓库拉取该版本的jar包 如果有该版本的jar包，就不会做任何行为 更新本地元文件：更新本地仓库jar包决定于本地元文件 maven-metadata-snapshot-nexus.xml，该文件的更新取决于resolver-status.properties文件 先去远程仓库获取maven-metadata-snapshot-nexus.xml文件，远程仓库中不存在此文件，那么会走下载流程 如果存在，读取resolver-status.properties中的lastUpdated参数，然后与当前的时间做比较，根据跟新策略是否需要下载（always/never/daily…) 附上stackOverflow上的回答：https://stackoverflow.com/questions/68003423/java-lang-illegalargumentexception-malformed-uxxxx-encoding-while-mvn-install","categories":[],"tags":[{"name":"maven","slug":"maven","permalink":"http://c89757.gitee.io/colinstar/tags/maven/"}]},{"title":"restTemplate","slug":"restTemplate","date":"2022-06-01T12:26:08.000Z","updated":"2022-06-09T15:25:23.404Z","comments":true,"path":"2022/06/01/restTemplate/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/01/restTemplate/","excerpt":"","text":"概述 最近项目有个新需求，需要将原来的接口支持https，虽然之前也有用过restTemplate，但一直未对其进行过深入了解，今天便来看一看 官方文档：https://docs.spring.io/spring-framework/docs/current/reference/html/integration.html#rest-client-accessRestTemplate 有两种方法可以创建restTemplate实例，一种是直接new，另一种是通过构建者构建出来 new 12345678// 直接newRestTemplate restTemplate = new RestTemplate();// 也可以调用有参构造，传入一个ClientHttpRequestFactory的实现类SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();factory.setConnectTimeout(3000);factory.setReadTimeout(3000);RestTemplate restTemplate = new RestTemplate(factory); build 123456RestTemplate restTemplate = new RestTemplateBuilder() .basicAuthentication(&quot;username&quot;, &quot;password&quot;) .setConnectTimeout(Duration.ofMillis(3000)) .setReadTimeout(Duration.ofMillis(3000)) .rootUri(&quot;http://example/base/&quot;) .build(); 常用API postForEntity 12345String url = &quot;http://www.baidu.com&quot;;HttpHeaders header = new HttpHeaders();header.add(&quot;auth&quot;,&quot;bearer ****&quot;);HttpEntity&lt;UserReqInfo&gt; httpEntity = new HttpEntity&lt;&gt;(new UserReqInfo(),header);ResponseEntity&lt;UserRespInfo&gt; orderResponseEntity = restTemplate.postForEntity(url, httpEntity, UserRespInfo.class); 对于基本类型和实体传参，必须使用MultiValueMap传参 ​ 什么是基本类型和实体传参呢？类似于form表单，如下 12@PostMapping(&quot;/test&quot;)public void test(UserDTO userDTO,Integer requestId)&#123;&#125; 而对于@Requestbody传参，需要使用HttpEntity传参 exhange exchange有以下几种重载方法 url：请求路径 method：请求方法 requestEntity：封装请求头和请求体 responseType：返回数据类型 uriVariables：支持PathVariable类型的数据 示例： 12345678910String url = &quot;http://www.baidu.com&quot;;// 创建http的headerHttpHeaders header = new HttpHeaders();header.add(&quot;auth&quot;,&quot;bearer ****&quot;);header.setContentType(MediaType.APPLICATION_JSON);Gson gson = new Gson();String json = gson.toJson(new UserReqInfo()); // UserReqInfo自定义实体类// 设置请求体和请求头HttpEntity&lt;String&gt; httpEntity = new HttpEntity&lt;&gt;(json,header);ResponseEntity&lt;UserRespInfo&gt; exchange = restTemplate.exchange(url, HttpMethod.POST, httpEntity, UserRespInfo.class); // UserRespInfo自定义实体类 execute restTemplate的所有get,post等等方法，最终都是调用的execute方法。 原理初始化 默认使用HttpUrlConnection，可以通过构造方法传入一个ClientHttpRequestFactory的实现类，以此来替换底层的执行引擎，常见的执行引擎包括HttpClient、Netty、OKHttp。 无参构造 调用RestTemplate无参构造初始化时，会去调用父类InterceptingHttpAccessor的无参构造，其又会去调用顶级父类HttpAccessor的无参构造，虽然无参构造啥也没做，但是可以看到，默认的ClientHttpRequestFactory在类加载时已经初始化为SimpleClientHttpRequestFactory了 有参构造 我们可以先创建一个HttpComponentsClientHttpRequestFactory的实例，该类的执行引擎用的是HttpClient exchange（）方法","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://c89757.gitee.io/colinstar/tags/spring/"}]},{"title":"堆排序","slug":"堆排序","date":"2022-03-24T11:44:57.000Z","updated":"2022-03-25T09:00:20.941Z","comments":true,"path":"2022/03/24/堆排序/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/03/24/%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"​ 堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最好，最坏，平均时间复杂度均为O（nlogn）,它也是不稳定的排序 堆是具有以下性质的完全二叉树： 每个结点的值都大于或等于其左右孩子节点的值，称为大顶堆 注意：没有要求结点的左孩子的值和右孩子的值的大小关系 每个结点的值都小于或等于其左右孩子的结点，称为小顶堆 大顶堆举例说明: 我们对堆中的结点按照层次进行编号，映射到数组中就是下面这个样子： [ 50 , 45 , 40 , 20 , 25 , 35 , 30 , 10 ,15] 大顶堆特点: arr[ i ] &gt;= arr [ 2 * i + 1 ] &amp;&amp; arr[ i ] &gt;= arr [ 2 * i + 2] // i对应第几个结点，i从0开始编号 小顶堆： 小顶堆：arr [ i ] &lt; = arr [ 2 * i + 1] &amp;&amp; arr [ i ] &lt;= arr [ 2 * i + 2] 一般升序采用大顶堆，降序采用小顶堆 堆排序基本思想： 1、将待排序序列构造成一个大顶堆 2、此时，整个序列的最大值就是顶堆的根节点 3、将其与末尾元素进行交换，此时末尾就为最大值 4、然后将剩余 n - 1个元素重新构造成一个堆，这样会得到 第n 个元素的次小值，如此反复执行，便能得到一个有序序列了 例题：给定一个数组 { 4， 6 ，8 ，5 ，9 }，要求使用堆排序法，将数组升序排序 图解： step1：构造初始堆。将给定无序序列构造成一个大顶堆 （ 一般升序采用大顶堆，降序采用小顶堆） 1、假设给定无序序列结构如下： 2、此时我们从最后一个非叶子结点开始（叶子结点不用调整，最后一个非叶子结点 arr.length / 2 -1 = 5 /2 - 1 = 1 , 也就是下面的6结点），从左至右，从下至上进行调整 arr.length / 2 -1 怎么来的？ 最后一个结点对应的数组下标为 arr.lenth - 1 ; 而 父结点 为 i 的左孩子下标为：2 * i + 1 ; 右结点为 2 * i + 2; 3、找到第二个非叶子节点4，先比较左右两边，9最大，4和9交换 4、这时，交换导致了子根 【 4， 5， 6】结构混乱，继续调整， 【 4，5 ，6 】中 6 最大 ，交换 4 和 6 此时，我们就将一个无序序列构造成了一个大顶堆 Step2：将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行 堆顶元素 9 和 末尾元素 4 进行交换 交换后重新调整结构，使其满足堆定义 再将堆顶元素8与末尾元素5进行交换，得到第二大元素8 （ 9 已经搞完了，相当于把它剔除了，所以这里末尾元素是5） 后续依次反复进行调整 总结： 将无序序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆 将堆顶元素与末尾元素交换，将最大元素“沉”到数组末端 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class HeapSort &#123; public static void main(String[] args) &#123; // 将数组升序排列 int array[] = &#123; 4 ,6 ,8 ,5 ,9 &#125;; heapSort(array); System.out.println(Arrays.toString(array)); &#125; /** * 0 1 2 3 4 * [4 ,6 ,8 ,5 ,9 ] * 4 * / \\ * 6 8 * / \\ * 8 9 * @param array */ public static void heapSort(int[] array)&#123; /** * step1 : 构造初始堆。将给定无序序列构造成一个大顶堆 */ // 最后一个非叶子节点 的下标为 array.length / 2 - 1; // 最后第二个非叶子节点 的下标为 最后一个非叶子结点的下标 - 1 for (int i = array.length / 2 - 1; i &gt;= 0 ; i -- ) &#123; adjustBigHeap(array,i, array.length); &#125; /** * step2 : 将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行 */ int length = array.length; for (int i = 0; i &lt; array.length; i++) &#123; int root = array[0]; // 堆顶元素 // 交换位置 array[0] = array[length - 1]; array[length - 1] = root; length -- ; // 重新调整堆 adjustBigHeap(array,0,length); // 0 ——&gt; 从堆顶开始调整 &#125; &#125; /** * 将一个数组 (把数组当成二叉树的层次排序) 调整成一个大顶堆 * 【以 index 为对应的非叶子节点的树进行调整 成大顶堆】 * @param array 待调整的数组 * @param index 非叶子结点在数组中的索引 * @param length 表示对多少个元素进行调整 * @return */ public static void adjustBigHeap(int[] array,int index, int length)&#123; if (index &lt; 0)&#123; return; &#125; int temp = array[index]; // 先取出当前元素的值,存入临时变量 // 开始调整 // 【 index * 2 + 1 】 左孩子的下标 // 【 i = i * 2 + 1 】 继续往下调整，也就是左孩子的左孩子 for (int i = index * 2 + 1; i &lt; length; i = i * 2 + 1) &#123; if ( i + 1 &lt; length &amp;&amp; array [ i ] &lt; array [ i + 1 ])&#123; // 左子结点 小于 右子结点 i = i + 1; // i 指向右子节点 &#125; if ( array [ i ] &gt; temp)&#123; // 子节点 大于当前节点 // 进行调换 array[ index ] = array[i]; // 把较大得值赋给当前节点 // array[i] = temp; index = i; // index 指向 与之调换的下标 逻辑上交换，物理上不交换 // 继续循环比较 &#125;else &#123; break; &#125; &#125; // for 循环结束后，已经将 以index为顶点 的树调整为大顶堆 array[index] = temp; // 将temp放到调整后的位置 &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://c89757.gitee.io/colinstar/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"堆","slug":"堆","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A0%86/"},{"name":"排序算法","slug":"排序算法","permalink":"http://c89757.gitee.io/colinstar/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"Synchronized详解","slug":"Synchronized详解","date":"2022-01-15T14:11:43.000Z","updated":"2022-03-25T08:58:33.756Z","comments":true,"path":"2022/01/15/Synchronized详解/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/01/15/Synchronized%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"设计同步器的意义 多线程编程中，有可能会出现多个线程同时访问同一个共享，可变资源的情况下，这个资源我们称之为临界资源；这种资源可能是：对象、变量、文件等 ​ 共享：资源可以由多个线程同时访问 ​ 可变：资源可以在其生命周期内被修改 由于线程执行的过程是不可控的，所以需要采用同步机制来协同对对象可变状态的访问 如何解决线程并发安全问题？ 实际上，所有的并发模式在执行线程安全问题时，采用的方案都是序列化访问临界资源。即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问 Java中，提供了两种方式来实现同步互斥访问：synchronized和lock同步器的本质就是加锁目的：序列化访问临界资源，即同一时刻只能有一个线程访问临界资源（同步互斥访问） synchronized内置锁是一种对象锁（锁的是对象而非引用），作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的 Synchronized底层原理​ synchronized是基于JVM内置锁实现，通过内部对象Monitor(监视器锁），基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock(互斥锁）实现，它是一个重量级锁，性能较低。当然，JVM内置锁在1.5之后版本做了重大的优化，如锁粗化(Lock Coarsening),锁消除（Lock Elimination）,轻量级锁（Lightweight Locking)、偏向锁（Biased Locking)、适应性自旋（Adaptive Spinning)等技术来减少锁操作的开销，内置锁的并发性能已经基本与Lock持平。Synchronized关键字被编译成字节码后会被翻译成 monitorenter 和monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置 每个对象都有一个自己的monitor(监视器锁)，加锁过程如下 Monitor监视器锁​ ​ 任何一个对象都有一个Monitor与之关联，当且一个Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。 monitorenter：每个对象都是一个监视器锁（Monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者 如果该线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1 如果其他线程占有该monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权 monitorexit：执行monitorexit的线程必须是object ref对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor,步再是这个monitor的所有者，其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权 ​ Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 123public synchronized void method()&#123; System.out.println(&quot;hello world&quot;);&#125; 经过javap解析后如下 ​ 方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED 标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个 monitor对象。 什么是monitor?​ ​ 可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。与一切皆对象一样，所有的java对象是天生的Monitor，每一个Java对象都有称为Monitor的潜质，因为在java的设计中，每一个Java对象自生成就带了把看不见的锁，它叫做内置锁或者Monitor锁；也就是通常说的Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始位置；在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） ​ ​ 我们知道synchronized加锁加在对象上，对象是如何记录锁状态的呢？答案是锁状态是被记录在每个对象的对象头（Mark Word）中，下面我们一起认识一下对象的内存布局 对象的内存布局​ ​ HotSpot虚拟机中，对象在内存中存储的布局分为三块区域：对象头（Header)、示例数据（Instance Data）和对齐填充（Padding） 对象头：保存对象的Hash码，GC年龄，对象锁，锁状态标致，偏向锁（线程）ID，偏向时间等，如果是数组对象，还会保存数组的长度。Java对象头一般占有2个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit，在64位虚拟机中，1个机器码是8个字节，也就是64bit)；但是如果对象是数组类型，则需要3个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确定数组的大小，所以用一块来记录数组的长度 实例数据：存放类的属性数据信息，包括父类的属性信息 对齐填充：由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐 ​ HotSpot虚拟机的对象头包括两部分信息，第一部分是”Mark Word”，用于存储对象自身的运行时数据，如哈希码（HashCode），GC分代年龄、锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等等，它是实现轻量级锁和偏向锁的关键。这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别位32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如：在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示 32位虚拟机 64位虚拟机 现在的虚拟机基本上是64位的，而64位的对象头有点浪费空间，JVM默认会开启指针压缩，所以基本上也是按32位的形式记录对象头的。 手动设置: -XX:+UseCompressedOops 哪些信息会被压缩？ 1.对象的全局静态变量(即类属性) 2.对象头信息：64位平台下，原生对象头大小为16字节，压缩后为12字节 3.对象的引用类型：64位平台下，引用类型本身大小为8字节，压缩后为4字节 4.对象数组类型：64位平台下，数组类型本身大小为24字节，压缩后16字节 对象头分析工具 OpenJDK开源工具包，JOL，maven坐标如下： 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 案例： 12345public static void main(String[] args) &#123; Object o = new Object(); // 打印markword System.out.println(ClassLayout.parseInstance(o).toPrintable());&#125; 打印出来的对象内存信息如下： 12345678java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1)//Mark Word 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一行为Mark Word 00000001 00000000 00000000 00000000 对象此时是无锁状态，前25位表示hashcode值，为什么hashcode是0？ 因为这个hashcode是jvm内置函数，类似于懒加载，此时还没有计算 此时将代码修改为如下： 1234567public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o)&#123; System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 打印的Mark Word为 00011000 11110111 00000010 00000010 即 00000010 00000010 11110111 00011000 发现对象头从无锁——&gt;轻量级锁 为什么不是偏向锁？ ​ 因为JVM会延迟去启动偏向锁，JVM启动时依赖大量的hashMap class对象等，这些对象里面也存在大量的同步块，JVM启动时内部也会去启动十几个线程，这些线程内部也会存在竞争，JVM为了避免造成 偏向锁 到 轻量级锁 到重量级锁 这种锁升级过程，减少锁升级的开销，所以把偏向锁推迟启动了 将代码睡眠几秒钟 12345678public static void main(String[] args) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(10); Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o)&#123; System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 12345678910111213141516171819java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) a8 f7 06 03 (10101000 11110111 00000110 00000011) (50788264) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一次打印的：00000101 00000000 00000000 00000000 就已经是偏向锁状态了，但是偏向锁的前23bit位会记录线程ID，此处并没有，这种 称之为匿名偏向，可偏向状态 如果一直处于偏向状态，无法重偏向的话，那么MarkWord会一直记录最后一个偏向线程的状态 锁的膨胀升级过程​ ​ 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁，但是锁的升级是单向的，也就是只能从低到高升级，不会出现锁的降级。从JDK1.6中默认是开启偏向锁和轻量级的，可以通过-XX:-UseBiasedLocking来禁用偏向锁 偏向锁：​ 偏向锁是Java6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁（会涉及到一些CAS操作，耗时）的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高了程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 默认开启偏向锁 开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0 关闭偏向锁：-XX:-UseBiasedLocking 轻量级锁：​ 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时，Mark Word的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁 自旋锁： 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程就可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环（这也是称为自旋的原因），一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。后没办法也就只能升级为重量级锁 锁消除: ​ 消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间。锁消除的依据是逃逸分析的数据支持 锁消除，前提是Java必须运行在server模式，（server模式会比client模式作更多的优化），同时必须开启逃逸分析 -XX:+DoEscapeAnalysis 开启逃逸分析 -XX:+EliminateLocks 表示开启锁消除 使用逃逸分析，编译器可以对代码做如下优化： 同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步 将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配 分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Netty","slug":"Netty","date":"2022-01-06T12:58:22.000Z","updated":"2022-03-25T08:55:54.425Z","comments":true,"path":"2022/01/06/Netty/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/01/06/Netty/","excerpt":"","text":"BIO&amp;NIO&amp;AIOBIO ​ blocking I/O , 即阻塞IO，同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时，服务端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善（实现多个客户连接服务器） 先看单线程的版本 12345678910111213141516public static void main(String[] args) throws IOException &#123; final ServerSocket serverSocket = new ServerSocket(9000); while (true)&#123; log.info(&quot;等待连接....&quot;); final Socket socket = serverSocket.accept(); log.info(&quot;建立连接&quot;); InputStream inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int read = inputStream.read(bytes); if (read != -1)&#123; log.info(&quot;收到消息：&#123;&#125;&quot;,new String(bytes,0,read)); &#125; socket.getOutputStream().write(&quot;已成功接收到消息&quot;.getBytes()); socket.getOutputStream().flush(); &#125; &#125; Debug启动程序，在serverSocket.accept()处打上断点，同时再下一行处也打上断点，然后我们点击idea调试的Resume Program按钮，让程序直接走完；我们会发现断点没有到达下一行，程序也没有停止，而是阻塞在了accept()里。 我们试着用telnet工具去连接程序 按下回车连接的同时，我们也会发现程序的断点跑到了下一行 我们再在 int read = inputStream.read(bytes);这一行及其下一行也打上断点； 程序来到inputStream.read(bytes)这一行，我们再次选择放掉这一个断点，发现此处程序也并没有来到下一行，也是在此处进行了阻塞 我们用telnet工具给服务端发送消息 回到程序，发现程序执行到了下一行 接下来我们重新开始，重新启动服务端，开启一个telnet（客户端1）去连接，但是不发送消息，让程序阻塞在int read = inputStream.read(bytes)这一行；与此同时，我们再另外开启一个telnet客户端（客户端2）去进行连接，然后发送消息给服务端 但是我们发现，控制台并没有任何消息打印； 我们此时在用客户端1去发送消息 发现客户端打印消息，但是打印hello2之前，输出了”建立连接“；说明此时我们其实客户端2并没有真正的连接上，而是阻塞在了serverSocket.accept()处 12final Socket socket = serverSocket.accept();log.info(&quot;建立连接&quot;); 在同一时刻，服务端只能响应一个客户端 解决方案我们可以在将代码改成多线程版本 12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4jpublic class TestBIO extends Thread&#123; private Socket socket; public TestBIO(Socket socket) &#123; this.socket = socket; &#125; public static void main(String[] args) throws IOException &#123; final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 10, 5000, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); log.info(&quot;等待连接....&quot;); final ServerSocket serverSocket = new ServerSocket(9000); while (true)&#123; Socket socket = serverSocket.accept(); log.info(&quot;建立连接&quot;); threadPoolExecutor.execute(new TestBIO(socket)); if (false)&#123; break;&#125; &#125; &#125; public static void handler(Socket socket) throws IOException &#123; InputStream inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int read = inputStream.read(bytes); if (read != -1)&#123; log.info(&quot;收到消息：&#123;&#125;&quot;,new String(bytes,0,read)); &#125; socket.getOutputStream().write(&quot;已成功接收到消息&quot;.getBytes()); socket.getOutputStream().flush(); &#125; @Override public void run() &#123; try &#123; handler(this.socket); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 我们再实验以上步骤 先开启telnet客户端1去连接阻塞，但是不发送消息 再开启telnet客户端2去连接，并发送消息 结果此次控制台能正确接收到消息 存在的问题​ 如果开辟大量线程，比较消耗资源，且如果我们用了线程池，如果我们线程池数量是500，某一瞬间并发量有1w，那后面的请求就只能阻塞等待。又或者500线程池，其中400个线程只是和你建立连接，并不立马发送消息给服务端，那这个线程会一直被这个连接给占用，其他人无法获取; 又或者用完线程给别人用时，线程的切换也是比较消耗资源的 IO代码里read操作是阻塞操作，如果连接不做数据读写会导致线程阻塞，浪费资源 如果线程很多，会导致服务器线程太大，压力太大 应用场景：BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高 NIO​ Non Blocking IO,或者读为New IO,同步非阻塞，服务器实现模式为一个线程可以处理多个请求（连接），客户端发送的连接请求都会注册到多路复用器selector上，多路复用器轮询到连接有IO请求就进行处理，JDK1.4开始引入 123456789101112131415161718192021222324252627282930313233343536373839@Slf4jpublic class TestNIO &#123; private static List&lt;SocketChannel&gt; channelList = new ArrayList&lt;&gt;(); public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); // 设置ServerSocketChannel为非阻塞 serverSocketChannel.configureBlocking(false); while (true) &#123; // 非阻塞模式accept方法不会阻塞，否则会阻塞 // NIO的非阻塞是由操作系统内部实现的，底层调用了linux内核的accept函数 SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) &#123; // 如果有客户端进行连接 log.info(&quot;连接成功&quot;); // 设置SocketChannel为非阻塞 socketChannel.configureBlocking(false); // 保存客户端连接在list中 channelList.add(socketChannel); &#125; // 遍历连接进行数据读取 Iterator&lt;SocketChannel&gt; iterator = channelList.iterator(); while (iterator.hasNext()) &#123; SocketChannel next = iterator.next(); ByteBuffer byteBuffer = ByteBuffer.allocate(128); // 非阻塞模式read方法不会阻塞 int len = next.read(byteBuffer); if (len &gt; 0) &#123; log.info(&quot;接收到消息: &#123;&#125;&quot;, new String(byteBuffer.array())); &#125; else if (len == -1) &#123; // 如果客户端断开，把socket从集合中删调 iterator.remove(); log.info(&quot;与客户端断开连接&quot;); &#125; &#125; &#125; &#125;&#125; 我们先后开启两个telnet客户端去连接服务端，发送消息，服务端都能接收到; 会一直循环去判断是否有新的连接请求，是否有连接发送消息 上述代码存在的问题： 如果连接数太多的话，会有大量的无效遍历 比如如果我现在有10万个连接，但是经常给服务端发消息的就那个几百个，但是每次都要去遍历所有的连接 我们可以将那些有数据交互的连接，存储在另外一个数据结构中，每次遍历只需要遍历那些有数据交互的连接 NIO引入多路复用器代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4jpublic class NioSelectorServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); // 设置ServerSocketChannel为非阻塞 serverSocketChannel.configureBlocking(false); // 打开selector处理Channel，即创建epoll Selector selector = Selector.open(); // 把ServerSocketChannel注册到selector上，并且selector监听客户端accept连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; // 阻塞等待需要处理的事件发生 selector.select(); // 获取selector中注册的全部事件的SelectionKey实例 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); // 遍历SelectionKey对事件进行处理 while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); // 如果是OP_ACCEPT事件，则进行连接获取和事件注册 if (key.isAcceptable())&#123; ServerSocketChannel channel =(ServerSocketChannel) key.channel(); final SocketChannel socketChannel = channel.accept(); socketChannel.configureBlocking(false); // 这里只注册了读事件，如果需要给客户端发送数据可以注册写事件 socketChannel.register(selector,SelectionKey.OP_READ); log.info(&quot;客户端连接成功&quot;); &#125;else if(key.isReadable())&#123; // 如果是OP_READ事件，则进行读取和打印 SocketChannel channel =(SocketChannel)key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int len = channel.read(byteBuffer); if (len &gt;0 )&#123; log.info(&quot;接收到消息:&#123;&#125;&quot;,new String(byteBuffer.array())); &#125;else if(len == -1)&#123; log.info(&quot;客户端断开连接&quot;); channel.close(); &#125; &#125; // 从事件集合里删除本次处理的key,防止下次select重复处理 iterator.remove(); &#125; &#125; &#125;&#125; NIO有三大核心组件：Channel(通道)，Buffer(缓冲区)，Selector(多路复用器) 1、channel类似于流，每个channel对应一个buffer缓冲区，buffer底层就是个数组 2、channel会注册到selector上，由selector根据channel独写事件的发生将其交由某个空闲的线程处理 3、NIO的Buffer和channe都是既可以读也可以写 先看一幅图 ​ 我们代码最开始处，创建了一个ServerSocketChannel，并绑定9000端口,并将ServerSocketChannel注册到selector上，并且selector监听客户端accept连接事件，注册上后会返回一个key,通过这个selectionKey可以找到与之绑定的ServerSocketChannel; ​ 我们在selector.select()处及其下一行打上断点，启动项目。 ​ 放掉断点让其走完，发现程序阻塞在了这一行； ​ 同样的，打开cmd，用telnet连接 1telnet localhost 9000 ​ ​ 连接上后，发现程序走到了下一行 ​ 继续往下走一行，获取到所有的selectionKey; 因为此时我们只有一个客户端进行连接，所以此处size是1 ​ 很显然我们此处是OP_ACCEPT事件 ​ 通过selectionKey可以拿到与之绑定的ServerSocketChannel，并让其与客户端建立连接,并把客户端对应的socketChannel也注册到selector上，并让其监听读事件（读是相当于服务端来的，也就是监听客户端发送过来的消息） ​ 我们一步一步调试，让程序走完，因为是死循环，在select处又会进行阻塞，因为此时既没有新的客户端连接进来，刚刚连接上的客户端也没有发送消息。 ​ 我们用telnet再给服务端发送一条消息 ​ 此时，程序停止了阻塞，走到了下一行 ​ 一步一步调试，很显然这次我们是OP_READ事件，通过key拿到与客户端对应的SocketChannel。也就是下图标识出来的部分，用它来读取客户端的数据 ​ 我们现在再另外开启一个telnet客户端，连接服务端 ​ 我们可以看到，现在有两个客户端，但是拿到的selectionKey只有一个，只针对那些发生的事件进行处理 ​ NIO底层在JDK1.4版本是用linux的内核函数select()或poll()来实现，跟上面最开始的代码类似，selector每次都会轮询所有的socketChannel看下哪个channel有读写事件，有的话就处理，没有就继续遍历，JDK1.5引入了epoll基于事件响应机制来优化NIO 几个核心APISelector.open();1Selector selector = Selector.open(); provider()方法里最终调用了下面的create()方法，发现其new 了一个WindowsSelectorProvider()。因为我们日常使用的是windows的jdk 123public static Selector open() throws IOException &#123; return SelectorProvider.provider().openSelector();&#125; 12345678public class DefaultSelectorProvider &#123; private DefaultSelectorProvider() &#123; &#125; public static SelectorProvider create() &#123; return new WindowsSelectorProvider(); &#125;&#125; 下载openJdk8u的源码，搜索DefaultSelectorProvider这个类，发现有三个，分别对应unix系统，mac系统，windows系统。我们接下来看unix系统对应的源码 unix系统create()方法的源码如下，发现和windows的有区别，如果是linux系统，会返回EPollSelectorProvider这个类 123456789public static SelectorProvider create() &#123; String osname = AccessController .doPrivileged(new GetPropertyAction(&quot;os.name&quot;)); if (osname.equals(&quot;SunOS&quot;)) return createProvider(&quot;sun.nio.ch.DevPollSelectorProvider&quot;); if (osname.equals(&quot;Linux&quot;)) return createProvider(&quot;sun.nio.ch.EPollSelectorProvider&quot;); return new sun.nio.ch.PollSelectorProvider();&#125; open()方法里会调用openSelector()这个方法，EPollSelectorProvider里的实现如下，直接new 了一个EPollSelectorImpl 1234567891011public class EPollSelectorProvider extends SelectorProviderImpl&#123; public AbstractSelector openSelector() throws IOException &#123; return new EPollSelectorImpl(this); &#125; public Channel inheritedChannel() throws IOException &#123; return InheritedChannel.getChannel(); &#125;&#125; 接着我们去看看EpollSelectorImpl这个类的构造函数，初始化的时候， new EPollArrayWrapper()创建了一个EPollArrayWrapper对象 123456789EPollSelectorImpl(SelectorProvider sp) throws IOException &#123; super(sp); long pipeFds = IOUtil.makePipe(false); fd0 = (int) (pipeFds &gt;&gt;&gt; 32); fd1 = (int) pipeFds; pollWrapper = new EPollArrayWrapper(); pollWrapper.initInterrupt(fd0, fd1); fdToKey = new HashMap&lt;&gt;();&#125; 紧接着我们看到EPollArrayWrapper的构造函数，里面调用了一个epollCreate（）方法 12345678910111213EPollArrayWrapper() throws IOException &#123; // creates the epoll file descriptor epfd = epollCreate(); // the epoll_event array passed to epoll_wait int allocationSize = NUM_EPOLLEVENTS * SIZE_EPOLLEVENT; pollArray = new AllocatedNativeObject(allocationSize, true); pollArrayAddress = pollArray.address(); // eventHigh needed when using file descriptors &gt; 64k if (OPEN_MAX &gt; MAX_UPDATE_ARRAY_SIZE) eventsHigh = new HashMap&lt;&gt;();&#125; ​ epollCreate是一个本地方法 （java的native方法是通过JNI，即java native interface来实现的，可以通过它来实现java与其他语言之间的交互） 1private native int epollCreate(); EPollArrayWrapper.c里找到这个epollCreate方法, epoll_create是linux的一个系统函数 12345678910111213JNIEXPORT jint JNICALLJava_sun_nio_ch_EPollArrayWrapper_epollCreate(JNIEnv *env, jobject this)&#123; /* * epoll_create expects a size as a hint to the kernel about how to * dimension internal structures. We can&#x27;t predict the size in advance. */ int epfd = epoll_create(256); if (epfd &lt; 0) &#123; JNU_ThrowIOExceptionWithLastError(env, &quot;epoll_create failed&quot;); &#125; return epfd;&#125; 我们在linux系统上执行 man epoll_create命令，查看这个函数的文档 -打开一个文件描述符，相当于创建了一个epoll对象，返回文件描述符的索引 int epfd = epoll_create(256) serverSocketChannel.register(…) 1serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); java.nio.channels.SelectableChannel#register(java.nio.channels.Selector, int) 12345public final SelectionKey register(Selector sel, int ops) throws ClosedChannelException&#123; return register(sel, ops, null);&#125; java.nio.channels.spi.AbstractSelectableChannel#register 这个方法里面最终又调用了一个register方法，我们再点进去 12345678910111213141516public final SelectionKey register(Selector sel, int ops, Object att) throws ClosedChannelException&#123; synchronized (regLock) &#123; ..... synchronized (keyLock) &#123; if (!isOpen()) throw new ClosedChannelException(); k = ((AbstractSelector)sel).register(this, ops, att); // 主要看这个register方法 addKey(k); &#125; &#125; ..... &#125;&#125; sun.nio.ch.SelectorImpl#register 这个里面又调用了一个implRegister（）方法，我们点进去是个抽象方法 protected abstract void implRegister(SelectionKeyImpl var1); 查看他的实现类，来到了WindowsSelectorImpl，这是windows系统的实现，我们去查看linux的implRegister的实现方法 123456789protected final SelectionKey register(AbstractSelectableChannel var1, int var2, Object var3) &#123; .... synchronized(this.publicKeys) &#123; this.implRegister(var4); &#125; .... &#125;&#125; sun.nio.ch.EPollSelectorImpl#implRegister pollWrapper.add(fd); fd是文件描述符，会根据这个索引找到这个文件（linux一切皆文件），在此处就是linux系统能够根据pd这个文件描述符找到这个创建好的serverSocketChannel； 这个pollWrapper就是上面Selector.open()里创建的pollWrapper 123456789protected void implRegister(SelectionKeyImpl ski) &#123; if (closed) throw new ClosedSelectorException(); SelChImpl ch = ski.channel; int fd = Integer.valueOf(ch.getFDVal()); fdToKey.put(fd, ski); pollWrapper.add(fd); keys.add(ski);&#125; selector.select(); 123Selector selector = Selector.open(); ....selector.select(); select是一个抽象方法 1public abstract int select() throws IOException; 点进实现类 sun.nio.ch.SelectorImpl#select() 123public int select() throws IOException &#123; return this.select(0L);&#125; lockAndDoSelect 1234567public int select(long var1) throws IOException &#123; if (var1 &lt; 0L) &#123; throw new IllegalArgumentException(&quot;Negative timeout&quot;); &#125; else &#123; return this.lockAndDoSelect(var1 == 0L ? -1L : var1); &#125;&#125; sun.nio.ch.SelectorImpl#lockAndDoSelect 123456789101112private int lockAndDoSelect(long var1) throws IOException &#123; ...... synchronized(this.publicKeys) &#123; synchronized(this.publicSelectedKeys) &#123; var10000 = this.doSelect(var1); &#125; &#125; ...... &#125; &#125;&#125; doSelect是一个抽象方法，点进实现类来到了WindowsSelectorImpl。同样的，我们需要看linux的实现EPollSelectorImpl 1protected abstract int doSelect(long var1) throws IOException; sun.nio.ch.EPollSelectorImpl#doSelect 1234567protected int doSelect(long timeout) throws IOException &#123; ....... pollWrapper.poll(timeout); ....... &#125; return numKeysUpdated;&#125; sun.nio.ch.EPollArrayWrapper#poll 123456789101112int poll(long timeout) throws IOException &#123; updateRegistrations(); updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd); for (int i=0; i&lt;updated; i++) &#123; if (getDescriptor(i) == incomingInterruptFD) &#123; interruptedIndex = i; interrupted = true; break; &#125; &#125; return updated;&#125; 先看updateRegistrations（）方法 updateRegistrations(); 此方法里又调用了一个epollCtl(epfd, opcode, fd, events) ，点进去，这是一个本地方法 private native void epollCtl(int epfd, int opcode, int fd, int events); 内部调用的就是linux函数epoll_ctl 123456789101112131415161718192021222324252627282930private void updateRegistrations() &#123; synchronized (updateLock) &#123; int j = 0; while (j &lt; updateCount) &#123; int fd = updateDescriptors[j]; short events = getUpdateEvents(fd); boolean isRegistered = registered.get(fd); int opcode = 0; if (events != KILLED) &#123; if (isRegistered) &#123; opcode = (events != 0) ? EPOLL_CTL_MOD : EPOLL_CTL_DEL; &#125; else &#123; opcode = (events != 0) ? EPOLL_CTL_ADD : 0; &#125; if (opcode != 0) &#123; epollCtl(epfd, opcode, fd, events); if (opcode == EPOLL_CTL_ADD) &#123; registered.set(fd); &#125; else if (opcode == EPOLL_CTL_DEL) &#123; registered.clear(fd); &#125; &#125; &#125; j++; &#125; updateCount = 0; &#125; &#125; 在linux系统上执行命令 1man epoll_ctl 查看此函数 epollCtl(epfd, opcode, fd, events); epfd epoll实例对应的文件描述符 fd socketChannel对应的文件描述符events 事件 参数opcode又以下几个值： 123EPOLL_CTL_ADD // 注册新的SocketChannel到epoll实例中，并关联事件eventEPOLL_CTL_DEL // 修改已经注册的SocketChannel的监听事件EPOLL_CTL_MOD // 从epoll中移除SocketChannel，并且忽略掉绑定的event epollCtl这个方法把SocketChannel和epoll关联起来 2.updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd); 再回到poll方法里，程序继续往下走，接着看epollWait这个方法，点进去也是一个本地方法，也是调用的操作系统内核函数 epoll_wait epoll_wait, epoll_pwait - wait for an I/O event on an epoll file descriptor epoll_wait的时候，会去查看sector里面的rdlist就绪列表里是否有数据，有数据就跳出阻塞，没有就阻塞住 利用操作系统回调函数，客户端有响应，把事件放进rdlist AIO（NIO 2.0） ​ 异步非阻塞，由操作系统完成后回调通知服务端程序启动线程去处理，一般适用于连接数较多并且连接时间较长的应用 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940public class TestAIO &#123; public static void main(String[] args) throws IOException &#123; AsynchronousServerSocketChannel serverSocketChannel = AsynchronousServerSocketChannel.open().bind(new InetSocketAddress(9000)); serverSocketChannel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Object&gt;() &#123; @Override public void completed(AsynchronousSocketChannel socketChannel, Object attachment) &#123; try &#123; System.out.println(&quot;2----&quot; + Thread.currentThread().getName()); // 再此接收客户端连接,如果不写这行代码后面的客户端连接不上服务端 serverSocketChannel.accept(attachment, this); System.out.println(socketChannel.getRemoteAddress()); ByteBuffer buffer = ByteBuffer.allocate(1024); socketChannel.read(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println(&quot;3---&quot; + Thread.currentThread().getName()); buffer.flip(); System.out.println(new String(buffer.array(), 0, result)); socketChannel.write(ByteBuffer.wrap(&quot;HelloClient&quot;.getBytes())); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); &#125; &#125;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, Object attachment) &#123; exc.printStackTrace(); &#125; &#125;); System.out.println(&quot;1---&quot;+Thread.currentThread().getName()); System.in.read(); &#125;&#125; NettyRector响应式编程模型 所谓响应式，类似于GUI编程中，给一个Button绑定一个或多个事件，对于点击事件，点击后会触发对应方法 基础的Reactor设计，单线程版本; 用一个Reactor去处理客户端的连接，以及读写 存在的问题：类比上面的NioSelectorServer类代码。selector.select()处会阻塞，同一时间如果有大量的读写事件发生，那么循环处理的时候，会耗费大量时间，而此时新进来的连接就会阻塞在selector.select()处。 我们可以引入线程池，将读写工作交给其他线程去处理 存在的问题：还是类比上面的NioSelectorServer类的代码；我们现在while (iterator.hasNext()) {….}循环去处理的时候，引入线程池，将读写事件交给线程池去处理；这样分发完后，主线程能很快的回到selector.select()处，阻塞监听新的事件。但是如果一时间的事件很多，那么分发都需要花费大量的时间，同样新进来的事件也得不到处理 引入两个Reactor，一个mainReactor专门用来处理连接事件。subReactor用来处理独写事件，并且把这些读写事件分发给线程池去完成 Demo NettyServer.java 1234567891011121314151617181920212223242526272829303132333435363738public class NettyServer &#123; public static void main(String[] args) &#123; // 创建两个线程组boss和worker;含有的子线程NioEventLoop的个数默认为cpu核数的两倍 // boss组只是处理连接请求，真正的和客户端业务处理，会交给worker NioEventLoopGroup bossGroup = new NioEventLoopGroup(1); // 相当于主Reactor NioEventLoopGroup workerGroup = new NioEventLoopGroup(8); // 相当于从Reactor try&#123; // 创建服务端的启动对象 ServerBootstrap serverBootstrap = new ServerBootstrap(); // 使用链式编程来配置参数 serverBootstrap.group(bossGroup,workerGroup) // 设置两个线程组 // 使用NioServerSocketChannel作为服务器的通道实现 .channel(NioServerSocketChannel.class) // 初始化服务器连接队列大小，服务端处理客户端连接请求是顺序处理的，所以同一时间处理一个客户端 // 多个客户端同时来连接的时候，服务端将不能处理的客户端连接请求放在队列中等待处理 .option(ChannelOption.SO_BACKLOG,1024) .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new NettyServerHandler()); &#125; &#125;); log.info(&quot;------netty server start...------&quot;); // 绑定一个端口并且同步，生成了一个ChannelFuture异步对象，通过isDone()等方法可以判断异步事件的执行情况 // 启动服务器(并绑定端口),bind是异步操作，sync方法是等待异步操作执行完毕 ChannelFuture sync = serverBootstrap.bind(9000).sync(); // 等待服务端监听端口关闭，closeFuture是异步操作 // 通过sync方法同步等待通道关闭处理完毕，这里会阻塞等待通道关闭，内部调用的是object.wait()方法 sync.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; NettyServerHandler.Java 123456789101112131415161718192021222324252627282930313233public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; /** * 读取客户端发送的消息 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf in = (ByteBuf) msg; System.out.println(in.toString(CharsetUtil.UTF_8)); &#125; /** * 数据读取完毕处理方法 */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; String msg = &quot;[来自服务端]:congratulations~连接成功&quot;; final ByteBuf byteBuf = Unpooled.copiedBuffer(msg.getBytes(CharsetUtil.UTF_8)); ctx.writeAndFlush(byteBuf); &#125; /** * 异常处理 */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // (4) // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); &#125;&#125; NettyClient.java 123456789101112131415161718192021222324252627public class NettyClient &#123; public static void main(String[] args) throws InterruptedException &#123; // 客户端需要一个事件循环组 NioEventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建客户端启动对象 Bootstrap b = new Bootstrap(); // (1) b.group(group); // (2) b.channel(NioSocketChannel.class); // (3) b.option(ChannelOption.SO_KEEPALIVE, true); // (4) b.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientChannel()); &#125; &#125;); System.out.println(&quot;netty client start....&quot;); // Start the client. ChannelFuture f = b.connect(&quot;127.0.0.1&quot;, 9000).sync(); // (5) // Wait until the connection is closed. f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; NettyClientChannel.java 1234567891011121314151617181920212223242526272829public class NettyClientChannel extends ChannelInboundHandlerAdapter &#123; /** * 当通道有读取事件时，也就是服务端发送消息 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf m = (ByteBuf) msg; try &#123; System.out.println(m.toString(CharsetUtil.UTF_8)); &#125; finally &#123; m.release(); &#125; &#125; /** * 当客户端连接服务器完成就会触发该方法 */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; final ChannelFuture f = ctx.writeAndFlush(Unpooled.copiedBuffer((&quot;[来自客户端]:hello server&quot; ).getBytes(CharsetUtil.UTF_8))); // (3) &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Netty模块组件 下面部分摘抄自官方文档https://netty.io/wiki/user-guide-for-4.x.html#wiki-h3-9 1、NioEventLoopGroup是一个处理 I/O 操作的多线程事件循环，Netty提供各种NioEventLoopGroup为不同类型的传输提供了各种实现；实现一个服务器端应用程序，因此NioEventLoopGroup将使用两个。第一个，通常称为“boss”，接受传入连接。第二个，通常称为“worker”，一旦boss接受连接并将接受的连接注册到worker;有多少线程使用和它们是如何映射到创建渠道取决于EventLoopGroup通过构造函数实现,甚至可能是可配置的 2、ServerBootstrap is a helper class that sets up a server；ServerBootstrap是一个设置服务器的辅助类。 Bootstrap与ServerBootstrap类似，除了它是非服务端通道，如客户端或无连接通道。 如果您只指定一个EventLoopGroup，它将同时用作boss组和worker组。但是，boss组不用于客户端。 NioSocketChannel被用来创建客户端Channel，而不是NioServerSocketChannel； 注意我们不像ServerBootstrap处，使用childOption(),因为客户端SocketChannel没有父级 我们应该调用connect()方法而不是bind()方法。 3、 Netty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接收客户端的连接, WorkerGroup专 门负责网络的 4 、BossGroup和WorkerGroup类型都是NioEventLoopGroup 5、NioEventLoopGroup 相当于一个事件循环线程组, 这个组中含有多个事件循环线程 ， 每一个事件循环线程是 NioEventLoop 6、每个NioEventLoop都有一个selector , 用于监听注册在其上的socketChannel的网络通讯 7、每个Boss NioEventLoop线程内部循环执行的步骤有 3 步 ​ 处理accept事件，与client建立连接，生成NioSocketChannle ​ 将NioSocketChannel注册到某个worker NIOEventLoop上的selector ​ 处理任务队列的任务，即runAllTasks 8、每个worker NIOEventLoop线程循环执行的步骤 ​ 轮询注册到自己selector上的所有NioSocketChannel 的read, write事件 ​ 处理 I/O 事件， 即read , write 事件， 在对应 NioSocketChannel 处理业务 ​ runAllTasks处理任务队列TaskQueue的任务 ，一些耗时的业务处理一般可以放入TaskQueue中慢慢处 理，这样不影响数据在 pipeline 中的流动处理 9、每个worker NIOEventLoop处理NioSocketChannel业务时，会使用 pipeline (管道)，管道中维护了很多 handler 处理器用来处理 channel 中的数据 Bootstrap、ServerBootstrap 一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组 件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。 Future、ChannelFuture 在Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理 但是可以等他执行完成或者直接注册一个监听，具体的实现就是通过Future和CahnnelFutures,他们可以注 册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件 Channel Netty网络通信的组件，能够用于执行网络I/O操作。Channel为用户提供 1、当前网络连接的通道的状态（例如是否打开？是否已连接） 2、网络连接的配置参数（例如接收缓冲区大小） 3、提供异步的网络I/O操作（如建立连接，读写，绑定端口），异步调用意味着任何I/O调用都将立即返回，并且不保证在调用结束时所请求的I/O操作已完成 4、调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上，可以I/O操作成功、失败或取消时回调通知调用方 5、支持关联I/O操作与对应的处理程序。 不同协议、不通的阻塞类型的连接都有不同的Channel类型与之对应 下面是一些常用的Channel类型： NioSocketChannel 异步的客户端TCP Socket连接 NioServerSocketChannel 异步的服务器端TCP Socket连接 NioDatagramChannel 异步的UDP连接 NioSctpChannel 异步的客户端Sctp连接 NioSctpServerChannel 异步的Sctp服务器端连接 这些通道涵盖了UDP和TCP网络IO以及文件IO Selector Netty基于Selector对象实现I/O多路复用，通过Selector一个线程可以监听多个连接的Channel事件。 当向一个Selector中注册Channel后，Selector内部的机制就可以自动不断地查询（Select）这些注册的Channel是否有已就绪的I/O事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多 个 Channel 。 NioEventLoop NioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop 的 run 方 法，执行 I/O 任务和非 I/O 任务： I/O任务，即selectionKey中ready的事件，如accept、connect、read、write等，由 processSelectedKeys 方 法触发。 非 IO 任务，添加到 taskQueue 中的任务，如 register0、bind0 等任务，由 runAllTasks 方法触发。 NioEventLoopGroup NioEventLoopGroup，主要管理eventLoop的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程（NioEventLoop)负责处理多个Channel上的事件，而一个Channel只对应于一个线程 ChannelHandler ChannelHandler是一个接口，处理I/O事件或拦截I/O操作，并将其转发到其ChannelPipeline(业务处理链)中的下一个处理程序 ChannelHandler本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类： ChannelInboundHandler 用于处理入站I/O事件 ChannelOutboundHandler 用于处理出站I/O操作 或者使用以下适配器类 ChannelInboundHandlerAdapter 用于处理入站I/O事件 ChannlOutboundHandler 用于处理出站I/O操作 ChannelHandlerContext 保存Channel相关的上下文信息，同时关联一个ChannelHandler对象 ChannelPipline ​ 保存ChannelHandler的List,用于处理或拦截Channel的入站事件和出站操作 ChannelPipeline实现了一中高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，事件的处理方式 在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下： ​ 一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组 成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。 read事件(入站事件)和write事件(出站事件)在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰 Netty架构图 ByteBuf ​ 从结构上来说，ByteBuf 由一串字节数组构成。数组中每个字节用来存放信息。 ByteBuf 提供了两个索引，一个用于读取数据，一个用于写入数据。这两个索引通过在字节数组中移动，来定 位需要读或者写信息的位置。 当从 ByteBuf 读取时，它的 readerIndex（读索引）将会根据读取的字节数递增。 同样，当写 ByteBuf 时，它的 writerIndex 也会根据写入的字节数进行递增。 ​ 需要注意的是极限的情况是 readerIndex 刚好读到了 writerIndex 写入的地方。 如果 readerIndex 超过了 writerIndex 的时候，Netty 会抛出 IndexOutOf-BoundsException 异常 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class TestByteBuf &#123; public static void main(String[] args) &#123; // 创建byteBuf对象，该对象内部包含一个字符数组byte[10] // 通过readerindex和writeindex和capacity，将buffer分成三个区域， // 已经读取的区域: [0,readerindex) 注意开闭区间 // 可读取的区域: [readerindex,writeindex) // 可写的区域: [writerindex,capacity） ByteBuf buffer = Unpooled.buffer(10); System.out.println(buffer); for (int i = 0; i &lt; 7; i++) &#123; buffer.writeByte(i); &#125; System.out.println(buffer); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(buffer.getByte(i)); &#125; System.out.println(buffer); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(buffer.readByte()); &#125; System.out.println(buffer); System.out.println(&quot;----------------&quot;); ByteBuf byteBuf2 = Unpooled.copiedBuffer(&quot;hello world&quot;, CharsetUtil.UTF_8); if (byteBuf2.hasArray())&#123; byte[] array = byteBuf2.array(); // 转成字符串 System.out.println(new String(array, CharsetUtil.UTF_8)); System.out.println(byteBuf2); System.out.println(byteBuf2.readerIndex()); System.out.println(byteBuf2.writerIndex()); System.out.println(byteBuf2.capacity()); System.out.println(byteBuf2.getByte(0)); // 获取数组0这个位置的字符h的ascii码，h=104 int len = byteBuf2.readableBytes(); // 可读的字节数 System.out.println(&quot;len = &quot; + len); &#125; // 范围读取 CharSequence charSequence = byteBuf2.getCharSequence(0, 6, CharsetUtil.UTF_8); System.out.println(charSequence.toString()); &#125;&#125; Netty编解码 Netty涉及到编解码的组件有Channel、ChannelHandler、ChannelPipe等 ChannelHandler ChannelHandler充当了处理入站和出站数据的应用程序逻辑容器，例如，实现ChannelInboundHandler接口（或 ChannelInboundHandlerAdapter)，你就可以接收入站事件和数据，这些数据随后会被你的应用程序的业务逻辑处理。当你要给连接的客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。你得业务逻辑通常写在一个或者多个ChannelInboundHandler中。ChannelOutboundHandler原理一样，只不过它用来处理出站数据的。 ChannelPipeline ChannelPipeline提供了ChannelHandler链的容器。以客户端应用程序为例，如果事件的运动方向时从客户端到服务端的，那么称为这些事件为出战的，即客户端发送给服务端的数据会通过pipeline中的一系列ChannelOutboundHandler(ChannelOutboundHandler)调用是从tail到head方向逐个调用每个handler的逻辑，并被这些handler处理，反之则称为入站的，入站只调用pipeline里的ChannelInboundHandler逻辑（ChannelInboundHandler调用是从head到tail方向逐个调用每个handler的逻辑 所谓的入站出站，是相当于客户端/服务端来说的，即收到消息为入站，消息发送为出站。入站会从head到tail经过一系列处理调用，但是入站只是会调用继承ChannelInboundHandler的逻辑，出站是从tail到尾进行处理调用，只会调用ChannelOutboundHandler 编码解码器 ​ 当你通过Netty发送或者接收一个消息时，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式（比如java对 象）；如果是出站消息，它会被编码成字节。 ​ Netty提供了一系列的编码解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。 ​ 以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由已知解码器 所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannelInboundHandler。Netty提供了很多编解码器，比如编解码字符串的StringEncoder和StringDecoder，编解码对象的ObjectEncoder和ObjectDecoder 等。 如果要实现高效的编解码可以用protobuf，但是protobuf需要维护大量的proto文件比较麻烦，现在一般可以使用protostuff。 protostuff是一个基于protobuf实现的序列化方法，它较于protobuf最明显的好处是，在几乎不损耗性能的情况下做到了不用我们 写.proto文件来实现序列化 maven坐标如下： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐api&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐core&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐runtime&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt; Netty粘包拆包 TCP是一个流协议，就是没有界限的一长串二进制数据。TCP作为传输层协议并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行数据包的划分，所以在业务上认为是一个完整的包，可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。 ​ 面向流的通信是无消息保护边界的。 ​ 如下图：client发送两个数据包D1和D2，但是server端可能会收到如下几种情况的数据 解决方案 1、消息定长度，数据传输的大小固定长度，例如每段长度固定100字节，不够空位补齐 2、在数据包尾部添加特殊分隔符，比如下划线等。前提是消息本体不能带分隔符 3、发送长度：发送每条数据的时候，将数据的长度一并发送。比如可以选取每条数据的前四位去记录长度，接受处理时可以根据长度判定开始和结束 Netty提供了多个解码器，可以进行分包的操作 LineBasedFrameDecoder (回车换行分包) DelimiterBasedFrameDecoder (特殊分隔符分包) FixedLengthFrameDecoder (固定长度报文分包) Netty心跳检测机制​ 在Netty中，实现心跳机制的关键是IDleStateHandler。 123456789101112........childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel)&#123; socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new StringEncoder()); // IdleStateEvent的readerIdleTime参数指定超过3秒还没收到客户端的连接，会触发 // IdleStateEvent事件并且交给下一个handler处理，下一个handler必须实现userEventTriggered方法处理对应事件 socketChannel.pipeline().addLast(new IdleStateHandler(3,0,0, TimeUnit.SECONDS)); socketChannel.pipeline().addLast(new HeartBeatServerHandler()); &#125;&#125;); 构造函数 12345678910111213141516171819202122232425262728293031323334353637383940// 读超时时间；写超时时间；所有的超时时间；时间单位public IdleStateHandler(long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; this(false, readerIdleTime, writerIdleTime, allIdleTime, unit);&#125;public IdleStateHandler(boolean observeOutput, long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; this.writeListener = new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; IdleStateHandler.this.lastWriteTime = IdleStateHandler.this.ticksInNanos(); IdleStateHandler.this.firstWriterIdleEvent = IdleStateHandler.this.firstAllIdleEvent=true; &#125; &#125;; this.firstReaderIdleEvent = true; this.firstWriterIdleEvent = true; this.firstAllIdleEvent = true; if (unit == null) &#123; throw new NullPointerException(&quot;unit&quot;); &#125; else &#123; this.observeOutput = observeOutput; if (readerIdleTime &lt;= 0L) &#123; this.readerIdleTimeNanos = 0L; &#125; else &#123; // 赋值 this.readerIdleTimeNanos = Math.max(unit.toNanos(readerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (writerIdleTime &lt;= 0L) &#123; this.writerIdleTimeNanos = 0L; // 赋值 &#125; else &#123; this.writerIdleTimeNanos = Math.max(unit.toNanos(writerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (allIdleTime &lt;= 0L) &#123; this.allIdleTimeNanos = 0L; // 赋值 &#125; else &#123; this.allIdleTimeNanos = Math.max(unit.toNanos(allIdleTime), MIN_TIMEOUT_NANOS); &#125; &#125;&#125; channelActive 1234public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; this.initialize(ctx); super.channelActive(ctx);&#125; initialize 1234567891011121314151617181920212223private void initialize(ChannelHandlerContext ctx) &#123; switch(this.state) &#123; case 1: case 2: return; default: this.state = 1; this.initOutputChanged(ctx); this.lastReadTime = this.lastWriteTime = this.ticksInNanos(); // lastReadTime,lastWriteTime赋初始值 if (this.readerIdleTimeNanos &gt; 0L) &#123; // readerIdleTimeNanos就是刚构造器里赋的值 this.readerIdleTimeout = this.schedule(ctx, new IdleStateHandler.ReaderIdleTimeoutTask(ctx), this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.writerIdleTimeNanos &gt; 0L) &#123; this.writerIdleTimeout = this.schedule(ctx, new IdleStateHandler.WriterIdleTimeoutTask(ctx), this.writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.allIdleTimeNanos &gt; 0L) &#123; this.allIdleTimeout = this.schedule(ctx, new IdleStateHandler.AllIdleTimeoutTask(ctx), this.allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; &#125;&#125; schedule 123ScheduledFuture&lt;?&gt; schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit) &#123; return ctx.executor().schedule(task, delay, unit);&#125; ChannelHandlerContext ctx是io.netty.channel.DefaultChannelHandlerContext实例，DefaultChannleHandlerContext又继承了AbstractChannelHandlerContext，在AbstractChannelHandlerContext中找到executor()方法，如下 123public EventExecutor executor() &#123; return (EventExecutor)(this.executor == null ? this.channel().eventLoop() : this.executor);&#125; ​ ctx.executor()会返回一个EventExecutor，其类图如下，跟ScheduledThreadPollExecutor定时线程池一样，其都继承或实现自ScheduledExecutorService接口 接着我们去看new IdleStateHandler.ReaderIdleTimeoutTask(ctx)，这个任务里的run方法 123456789101112131415161718192021222324protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = IdleStateHandler.this.readerIdleTimeNanos; if (!IdleStateHandler.this.reading) &#123; // nextDelay = readerIdleTimeNanos - (当前时间 - lastReadTime) // channelReadComplete()方法里，会更新lastReadTime // 其实就是在计算 读的时间间隔是否超过设定的时间 nextDelay -= IdleStateHandler.this.ticksInNanos() - IdleStateHandler.this.lastReadTime; &#125; if (nextDelay &lt;= 0L) &#123; // 小于等于0，即超时了走这里 IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, IdleStateHandler.this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); // 还会提交任务，延迟时间为readerIdleTimeNanos boolean first = IdleStateHandler.this.firstReaderIdleEvent;// 构造函数赋初始值为true IdleStateHandler.this.firstReaderIdleEvent = false; try &#123; IdleStateEvent event = IdleStateHandler.this.newIdleStateEvent(IdleState.READER_IDLE, first); IdleStateHandler.this.channelIdle(ctx, event); &#125; catch (Throwable var6) &#123; ctx.fireExceptionCaught(var6); &#125; &#125; else &#123; IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125;&#125; 123protected void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception &#123; ctx.fireUserEventTriggered(evt); // 会调用到下一个handler&#125; 源码剖析NioEventLoopGroup12NioEventLoopGroup bossGroup = new NioEventLoopGroup(1);NioEventLoopGroup workerGroup = new NioEventLoopGroup(); 构造函数 1234567891011121314151617181920public NioEventLoopGroup() &#123; this(0);&#125;public NioEventLoopGroup(int nThreads) &#123; this(nThreads, (Executor)null);&#125;public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider()); //SelectorProvider.provider()就是前面NIO所说的EPollSelectorProvider,详情看Selector.open()&#125;.......// 无参构造最终会调用这个有参构造 public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, SelectorProvider selectorProvider, SelectStrategyFactory selectStrategyFactory) &#123; super(nThreads, threadFactory, new Object[]&#123;selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject()&#125;); //调用父类MultithreadEventLoopGroup的构造器 &#125; io.netty.channel.MultithreadEventLoopGroup 123456private static final int DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt(&quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2));protected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args); //继续调用父类构造器，nThreads = 0的话，会传入默认的线程数，cpu核数*2&#125; io.netty.util.concurrent.MultithreadEventExecutorGroup 123protected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object... args) &#123; this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);&#125; 最终会调用MultithreadEventExecutorGroup类的这个构造方法 123456789101112131415161718192021222324252627282930protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; // nThreads = 16，executor = null this.terminatedChildren = new AtomicInteger(); this.terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE); if (nThreads &lt;= 0) &#123; throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); &#125; else &#123; if (executor == null) &#123; // 创建一个线程池 executor = new ThreadPerTaskExecutor(this.newDefaultThreadFactory()); &#125; this.children = new EventExecutor[nThreads]; // 创建一个EventExecutor数组，长度为nThreads（16） int j; for(int i = 0; i &lt; nThreads; ++i) &#123; boolean success = false; boolean var18 = false; try &#123; var18 = true; // 循环遍历，对数组中的每个元素赋值；会去new NioEventLoop(...) this.children[i] = this.newChild((Executor)executor, args); success = true; var18 = false; &#125; catch (Exception var19) &#123; throw new IllegalStateException(&quot;failed to create a child event loop&quot;, var19); &#125; finally &#123; ....... &#125;&#125; newChild() io.netty.channel.nio.NioEventLoopGroup#newChild 123protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider)args[0], ((SelectStrategyFactory)args[1]).newSelectStrategy(), (RejectedExecutionHandler)args[2]);&#125; io.netty.channel.nio.NioEventLoop 构造函数 public final class NioEventLoop extends SingleThreadEventLoop 1234567891011121314NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); // 调用父类构造器,里面会创建一个阻塞队列taskQueue if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; else if (strategy == null) &#123; throw new NullPointerException(&quot;selectStrategy&quot;); &#125; else &#123; this.provider = selectorProvider; NioEventLoop.SelectorTuple selectorTuple = this.openSelector(); // 类比前面NIO的代码，创建selector this.selector = selectorTuple.selector; this.unwrappedSelector = selectorTuple.unwrappedSelector; this.selectStrategy = strategy; &#125;&#125; io.netty.channel.SingleThreadEventLoop 构造函数 public abstract class SingleThreadEventLoop extends SingleThreadEventExecutor implements EventLoop 1234protected SingleThreadEventLoop(EventLoopGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler); this.tailTasks = this.newTaskQueue(maxPendingTasks);&#125; io.netty.util.concurrent.SingleThreadEventExecutor 构造函数 12345678910111213141516protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.threadLock = new Semaphore(0); this.shutdownHooks = new LinkedHashSet(); this.state = 1; this.terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ThreadExecutorMap.apply(executor, this); this.taskQueue = this.newTaskQueue(this.maxPendingTasks); // 创建阻塞队列 this.rejectedExecutionHandler = (RejectedExecutionHandler)ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;);&#125;protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) &#123; return new LinkedBlockingQueue(maxPendingTasks);&#125; ServerBootstrap 12ServerBootstrap serverBootstrap = new ServerBootstrap();serverBootstrap.group(bossGroup,workerGroup)..... ServerBootstrap构造器为空方法，没有做什么逻辑处理 group(bossGroup,workerGroup)1234567891011public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &#123; super.group(parentGroup); if (childGroup == null) &#123; throw new NullPointerException(&quot;childGroup&quot;); &#125; else if (this.childGroup != null) &#123; throw new IllegalStateException(&quot;childGroup set already&quot;); &#125; else &#123; this.childGroup = childGroup; return this; &#125;&#125; io.netty.bootstrap.AbstractBootstrap#group public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable {} 12345678910public B group(EventLoopGroup group) &#123; if (group == null) &#123; throw new NullPointerException(&quot;group&quot;); &#125; else if (this.group != null) &#123; throw new IllegalStateException(&quot;group set already&quot;); &#125; else &#123; this.group = group; // 赋值 return this.self(); &#125;&#125; channel(NioServerSocketChannel.class)1234567public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException(&quot;channelClass&quot;); &#125; else &#123; return this.channelFactory((new ReflectiveChannelFactory(channelClass))); &#125;&#125; new ReflectiveChannelFactory(channelClass) 12345678910private final Constructor&lt;? extends T&gt; constructor; // 成员属性public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) &#123; ObjectUtil.checkNotNull(clazz, &quot;clazz&quot;); try &#123; this.constructor = clazz.getConstructor(); // 获取传进来class的构造函数，并赋值给成员属性 &#125; catch (NoSuchMethodException var3) &#123; throw new IllegalArgumentException(&quot;Class &quot; + StringUtil.simpleClassName(clazz) + &quot; does not have a public non-arg constructor&quot;, var3); &#125; this.channelFactory((new ReflectiveChannelFactory(channelClass))); channelFactory()方法,就是将channelFactory赋值给成员属性 123456public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) &#123; ....... this.channelFactory = channelFactory; return this.self(); &#125;&#125; option(ChannelOption.SO_BACKLOG,1024)12345678910111213141516171819private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = new LinkedHashMap(); // 成员属性public &lt;T&gt; B option(ChannelOption&lt;T&gt; option, T value) &#123; if (option == null) &#123; throw new NullPointerException(&quot;option&quot;); &#125; else &#123; if (value == null) &#123; synchronized(this.options) &#123; this.options.remove(option); &#125; &#125; else &#123; synchronized(this.options) &#123; this.options.put(option, value); // 就是把传进来的key,value放进map &#125; &#125; return this.self(); &#125;&#125; childHandler(new ChannelInitializer() {…}handler()是发生在初始化的时候，childHandler()是发生在客户端连接之后 .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline().addLast(new ….); }}); 12345678910private volatile ChannelHandler childHandler; // 成员属性public ServerBootstrap childHandler(ChannelHandler childHandler) &#123; if (childHandler == null) &#123; throw new NullPointerException(&quot;childHandler&quot;); &#125; else &#123; this.childHandler = childHandler; return this; &#125;&#125; bind ChannelFuture cf = serverBootstrap.bind(ip,port); ServerBootstrap继承AbstractBootstrap，bind是父类AbstractBootstrap的方法 123public ChannelFuture bind(int inetPort) &#123; return this.bind(new InetSocketAddress(inetPort));&#125; 调用重载方法 12345678public ChannelFuture bind(SocketAddress localAddress) &#123; this.validate(); // 参数校验 if (localAddress == null) &#123; throw new NullPointerException(&quot;localAddress&quot;); &#125; else &#123; return this.doBind(localAddress); &#125;&#125; validate方法 校验成员属性是否有值,也就是group()，channel()配置的那些 123456789public B validate() &#123; if (this.group == null) &#123; throw new IllegalStateException(&quot;group not set&quot;); &#125; else if (this.channelFactory == null) &#123; throw new IllegalStateException(&quot;channel or channelFactory not set&quot;); &#125; else &#123; return this.self(); &#125;&#125; this.doBind(localAddress)方法 1234567891011121314151617181920212223242526private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = this.initAndRegister(); // ① final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; else if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); // ② return promise; &#125; else &#123; final AbstractBootstrap.PendingRegistrationPromise promise = new AbstractBootstrap.PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; promise.setFailure(cause); &#125; else &#123; promise.registered(); AbstractBootstrap.doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; this.initAndRegister()方法1234567891011121314151617181920212223final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; // channelFactory就是channel方法赋值的 ReflectiveChannelFactory // ReflectiveChannelFactory的newChannel()方法主要是: return (Channel)this.constructor.newInstance(); // 如前文所说，constructor也是channel方法赋值的，我们传进来的是NioServerSocketChannel.class channel = this.channelFactory.newChannel(); this.init(channel); &#125; catch (Throwable var3) &#123; ...... &#125; ChannelFuture regFuture = this.config().group().register(channel); // 将NioServerSocketChannel注册 if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture;&#125; NioServerSocketChannel的无参构造：12345private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); // 成员属性public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER));&#125; 先看newSocket()方法 1234567private static java.nio.channels.ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; return provider.openServerSocketChannel(); // 类比文章开头的NIO代码，几乎一模一样 会去创建ServerSocketChannel对象 &#125; catch (IOException var2) &#123; throw new ChannelException(&quot;Failed to open a server socket.&quot;, var2); &#125;&#125; this(newSocket(DEFAULT_SELECTOR_PROVIDER));调用重载的构造器 1234public NioServerSocketChannel(java.nio.channels.ServerSocketChannel channel) &#123; super((Channel)null, channel, SelectionKey.OP_ACCEPT); // SelectionKey.OP_ACCEPT 连接事件 this.config = new NioServerSocketChannel.NioServerSocketChannelConfig(this, this.javaChannel().socket());&#125; 父类构造器 12345678910111213141516171819202122232425262728293031323334353637protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent, ch, readInterestOp); // ① 继续调用父类构造器，如下&#125;protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); // ② 继续往上调用,代码如下 this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); // 设置ServerSocketChannel为非阻塞 &#125; catch (IOException var7) &#123; ...... &#125;&#125;protected AbstractChannel(Channel parent) &#123; // ③ this.parent = parent; this.id = this.newId(); this.unsafe = this.newUnsafe(); this.pipeline = this.newChannelPipeline(); // 创造pipeline&#125;protected DefaultChannelPipeline newChannelPipeline() &#123; // ④ return new DefaultChannelPipeline(this);&#125;protected DefaultChannelPipeline(Channel channel) &#123; // ⑤ this.channel = (Channel)ObjectUtil.checkNotNull(channel, &quot;channel&quot;); this.succeededFuture = new SucceededChannelFuture(channel, (EventExecutor)null); this.voidPromise = new VoidChannelPromise(channel, true); // 创建尾部节点，TailContext与HeadContext都间接实现了ChannelHandlerContext，AbstractChannelHandlerContext实现了它 // class TailContext extends AbstractChannelHandlerContext implements ChannelInboundHandler this.tail = new DefaultChannelPipeline.TailContext(this); this.head = new DefaultChannelPipeline.HeadContext(this); // 创建头部节点 this.head.next = this.tail; // 首尾互指 this.tail.prev = this.head;&#125; ch.configureBlocking(false); 即前面NIO代码的如下地方： this.init(channel); this.init()是一个抽象方法，ServerBootstrap中对应实现如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = new LinkedHashMap(); // AbstractBootstrap中的成员属性void init(Channel channel) throws Exception &#123; //channel ——&gt; NioServerSocketChannel实例 // options0（）是父类AbstractBootstrap方法，具体逻辑就是 return this.options; // this.options是前文所说的option()方法赋的值 Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = this.options0(); synchronized(options) &#123; // 会去遍历options,给nioServerSocketChannel里的成员属性ServerSocketChannelConfig赋值 setChannelOptions(channel, options, logger); ， &#125; Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = this.attrs0(); synchronized(attrs) &#123; Iterator var5 = attrs.entrySet().iterator(); while(true) &#123; if (!var5.hasNext()) &#123; break; &#125; Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e = (Entry)var5.next(); AttributeKey&lt;Object&gt; key = (AttributeKey)e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ChannelPipeline p = channel.pipeline(); // 拿到NioServerSocketChannel中的pipeline final EventLoopGroup currentChildGroup = this.childGroup; final ChannelHandler currentChildHandler = this.childHandler; final Entry[] currentChildOptions; synchronized(this.childOptions) &#123; currentChildOptions = (Entry[])this.childOptions.entrySet().toArray(newOptionArray(0)); &#125; final Entry[] currentChildAttrs; synchronized(this.childAttrs) &#123; currentChildAttrs = (Entry[])this.childAttrs.entrySet().toArray(newAttrArray(0)); &#125; p.addLast(new ChannelHandler[]&#123;new ChannelInitializer&lt;Channel&gt;() &#123; // 往pipeline里添加一个handler public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = ServerBootstrap.this.config.handler(); if (handler != null) &#123; pipeline.addLast(new ChannelHandler[]&#123;handler&#125;); &#125; ch.eventLoop().execute(new Runnable() &#123; public void run() &#123; pipeline.addLast(new ChannelHandler[]&#123;new ServerBootstrap.ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)&#125;); &#125; &#125;); &#125; &#125;&#125;);&#125; this.config().group().register(channel); this.config()返回一个ServerBootstrapConfig对象 1public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); //抽象方法 ServerBootstarp中的实现如下 12345private final ServerBootstrapConfig config = new ServerBootstrapConfig(this); // 成员属性public final ServerBootstrapConfig config() &#123; return this.config;&#125; ServerBootstrapConfig的构造方法如下： 123456789101112ServerBootstrapConfig(ServerBootstrap bootstrap) &#123; super(bootstrap); // 往上调用&#125;public abstract class AbstractBootstrapConfig&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; &#123; protected final B bootstrap; protected AbstractBootstrapConfig(B bootstrap) &#123; // 将ServerBootstarp赋值给成员属性 this.bootstrap = (AbstractBootstrap)ObjectUtil.checkNotNull(bootstrap, &quot;bootstrap&quot;); &#125;&#125; group()方法 123public final EventLoopGroup group() &#123; return this.bootstrap.group(); // this.bootstrap就是ServerBootstrap实例&#125; 12345volatile EventLoopGroup group; // 成员属性；具体在前文所说的ServerBootstrap里的group方法里赋的值public final EventLoopGroup group() &#123; return this.group; // 就是NioEventLoopGroup，准确来说是boss线程组。&#125; register(channel)方法 ​ 前面的this.config().group()会返回NioEventLoopGroup，register是抽象方法；而NioEventLoopGroup继承MultithreadEventLoopGroup，我们看MultithreadEventLoopGroup里的实现 1234567public ChannelFuture register(Channel channel) &#123; // channel ——&gt; NioServerSocketChannel return this.next().register(channel);&#125;public EventLoop next() &#123; return (EventLoop)super.next(); // 拿一个NioEventLoop线程，前面所说会创建(默认长度为16的)children数组，并循环遍历对每一个赋值&#125; ​ 接着继续跟进返回的nioEventLoop的register方法，NioEventLoop继承SingleThreadEventLoop，所以我们看它里面的实现 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 123public ChannelFuture register(Channel channel) &#123; return this.register((ChannelPromise)(new DefaultChannelPromise(channel, this)));&#125; 调用重载方法 12345public ChannelFuture register(ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); // this ————&gt; NioEventLoop return promise;&#125; io.netty.channel.AbstractChannel.AbstractUnsafe#register 123456789101112131415161718192021public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; ...... &#125; else &#123; AbstractChannel.this.eventLoop = eventLoop; // 将传进来的NioEventLoop赋值给成员属性 if (eventLoop.inEventLoop()) &#123; // 判断当前线程是否是NioEventLoop中的线程 this.register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; public void run() &#123; AbstractUnsafe.this.register0(promise); &#125; &#125;); &#125; catch (Throwable var4) &#123; ...... &#125; &#125; &#125;&#125; 先看excute方法做了什么 io.netty.util.concurrent.SingleThreadEventExecutor#execute 123456789101112131415161718192021222324252627282930public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; else &#123; boolean inEventLoop = this.inEventLoop(); this.addTask(task); // 将任务添加到taskQueue队列 if (!inEventLoop) &#123; this.startThread(); if (this.isShutdown()) &#123; boolean reject = false; try &#123; if (this.removeTask(task)) &#123; reject = true; &#125; &#125; catch (UnsupportedOperationException var5) &#123; &#125; if (reject) &#123; reject(); &#125; &#125; &#125; if (!this.addTaskWakesUp &amp;&amp; this.wakesUpForTask(task)) &#123; this.wakeup(inEventLoop); &#125; &#125;&#125; 123456789101112131415private void doStartThread() &#123; this.executor.execute(new Runnable() &#123; public void run() &#123; .... label1907: &#123; try &#123; var112 = true; SingleThreadEventExecutor.this.run(); // 调用NioEventLoop的run方法 success = true; var112 = false; break label1907; &#125; catch (Throwable var119) &#123; ....... &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected void run() &#123; while(true) &#123; while(true) &#123; while(true) &#123; try &#123; try &#123; switch(this.selectStrategy.calculateStrategy(this.selectNowSupplier, this.hasTasks())) &#123; case -3: case -1: // select()，类比NIO代码 // 方法里面会去调用 selector.select(timeoutMillis);超时等待 this.select(this.wakenUp.getAndSet(false)); if (this.wakenUp.get()) &#123; this.selector.wakeup(); &#125; break; case -2: continue; &#125; &#125; catch (IOException var23) &#123; this.rebuildSelector0(); handleLoopException(var23); continue; &#125; this.cancelledKeys = 0; this.needsToSelectAgain = false; int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; this.processSelectedKeys(); // 类比NIO代码,拿到SelectionKey &#125; finally &#123; this.runAllTasks(); // 执行任务 &#125; &#125; else &#123; long ioStartTime = System.nanoTime(); boolean var14 = false; try &#123; var14 = true; this.processSelectedKeys(); var14 = false; &#125; finally &#123; if (var14) &#123; long ioTime = System.nanoTime() - ioStartTime; this.runAllTasks(ioTime * (long)(100 - ioRatio) / (long)ioRatio); &#125; &#125; long ioTime = System.nanoTime() - ioStartTime; this.runAllTasks(ioTime * (long)(100 - ioRatio) / (long)ioRatio); &#125; &#125; catch (Throwable var24) &#123; handleLoopException(var24); &#125; break; &#125; ....... &#125; &#125;&#125; 1234567891011121314151617181920protected boolean runAllTasks() &#123; assert this.inEventLoop(); boolean ranAtLeastOne = false; boolean fetchedAll; do &#123; fetchedAll = this.fetchFromScheduledTaskQueue(); if (this.runAllTasksFrom(this.taskQueue)) &#123; // 从队列中获取任务并执行 ranAtLeastOne = true; &#125; &#125; while(!fetchedAll); if (ranAtLeastOne) &#123; this.lastExecutionTime = ScheduledFutureTask.nanoTime(); &#125; this.afterRunningAllTasks(); return ranAtLeastOne;&#125; 回过头来看，执行任务的逻辑，即刚刚提交任务的run方法 eventLoop.execute(new Runnable() { public void run() { AbstractUnsafe.this.register0(promise); }}); 123456789101112131415161718192021222324252627private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !this.ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = this.neverRegistered; AbstractChannel.this.doRegister(); // 注册 this.neverRegistered = false; AbstractChannel.this.registered = true; AbstractChannel.this.pipeline.invokeHandlerAddedIfNeeded(); this.safeSetSuccess(promise); AbstractChannel.this.pipeline.fireChannelRegistered(); // 责任链调用pipeline中的handler if (AbstractChannel.this.isActive()) &#123; if (firstRegistration) &#123; AbstractChannel.this.pipeline.fireChannelActive(); &#125; else if (AbstractChannel.this.config().isAutoRead()) &#123; this.beginRead(); &#125; &#125; &#125; catch (Throwable var3) &#123; this.closeForcibly(); AbstractChannel.this.closeFuture.setClosed(); this.safeSetFailure(promise, var3); &#125;&#125; 12345678910111213141516protected void doRegister() throws Exception &#123; boolean selected = false; while(true) &#123; try &#123; this.selectionKey = this.javaChannel().register(this.eventLoop().unwrappedSelector(), 0, this); // 将serverSocketChannel注册到selector上，并让其对 return; &#125; catch (CancelledKeyException var3) &#123; if (selected) &#123; throw var3; &#125; this.eventLoop().selectNow(); selected = true; &#125; &#125; &#125; 1234public final ChannelPipeline fireChannelRegistered() &#123; AbstractChannelHandlerContext.invokeChannelRegistered(this.head); // 将pipeline中的头节点传进去 return this;&#125; 12345678910111213static void invokeChannelRegistered(final AbstractChannelHandlerContext next) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelRegistered(); &#125; else &#123; executor.execute(new Runnable() &#123; // 接着执行 public void run() &#123; next.invokeChannelRegistered(); &#125; &#125;); &#125;&#125; 流程图 无锁串行化​ 大多数场景下，并行多线程处理可以提升系统的并发能力。但是，如果对于共享资源的并发访问处理不当，会带来严重的锁竞争，这最终会导致性能的下降。为了尽可能的避免锁竞争带来的性能损耗，可以通过串行化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程的切换，这样就避免了多线程竞争和同步锁。NIO的多路复用就是一种无锁串行化的设计思想。为了尽可能提升性能，Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。表面上来看，串行化的设计似乎CPU利用率不高，并发成都不够，但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优 Netty的NioEventLoop读到消息之后，直接调用ChannelPipeline的fireChannelRead(Object msg)，只要用户不主动切换线程，一直会由NioEventLoop调到用户的handler,期间不进行线程切换 零拷贝（直接内存的使用） 直接内存 直接内存Direct Memory,并不是虚拟机运行时数据区的一部分，某些情况下这部分内存也会被频繁地使用，而且也可能导致OOM,Java里用DirectByteBuffer可以分配一块直接内存(堆外内存) ​ 直接内存申请较慢，但访问效率高。在java虚拟机实现上，本地IO一般会直接操作直接内存（直接内存-&gt;系统调用 -&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存-&gt;直接内存-&gt;系统调用-&gt;硬盘/网卡）。 ​ Netty的接收和发送ByteBuf采用DIRECT BUFFERS ， 使用堆外内存进行Scoket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的JVM堆内存（HEAP BUFFERS)进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才能写入Socket中，Jvm堆内存的数据是不能写入Socket中的。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 优点： 不占用堆内存空间，减少GC发生的频率 java虚拟机实现上，本地IO会直接操作直接内存（直接内存——&gt;系统调用——&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存——&gt;直接内存——&gt;系统调用——&gt;硬盘/网卡） 缺点： 初始分配较慢 没有JVM直接帮助管理内存，容易发生内存溢出，为了避免一直没有FULL GC，最终导致直接内存把物理内存耗完。我们可以指定直接内存的最大值，通过-XX:MaxDirectMemorySize来指定，当达到阈值的时候，调用system.gc来进行一次FULL GC，间接把那些没有被使用的直接内存回收掉 ByteBuf内存池设计 ​ 随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但是对于缓冲区Buffer(相当于一个内存块)，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作，为了尽量重用缓冲区，Netty提供了基于ByteBuffer内存池的缓冲区重用机制。需要的时候直接从池子里获取ByteBuf使用即可，使用完毕之后就重新放回池子里去。 灵活的TCP参数配置能力​ 合理设置TCP参数在某些场景下对于性能的提升可以起到显著的效果，例如接收缓冲区SO_RCVBUF和发送缓冲区SO_SNDBUF。如果设置不当，对性能的影响是非常大的。通常建议值为128k或者256k Netty在启动辅助类ChannelOption中可以灵活的配置TCP参数，满足不同的用户场景 ByteBuf扩容机制 minNewCapacity：表示用户需要写入的值大小 threshold：阈值，为bytebuf内部设定容量的最大值 maxCapacity：Netty最大能接受的容量大小，一般为int的最大值","categories":[{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/categories/netty/"}],"tags":[{"name":"nio","slug":"nio","permalink":"http://c89757.gitee.io/colinstar/tags/nio/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/tags/netty/"}]},{"title":"关于count(*)","slug":"关于count()","date":"2021-12-22T12:09:37.000Z","updated":"2021-12-22T13:01:32.776Z","comments":true,"path":"2021/12/22/关于count()/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/22/%E5%85%B3%E4%BA%8Ecount()/","excerpt":"","text":"count(*)的不同实现方式 在 msyql 引擎中，count（*）有不同的实现方式 MyISAM引擎把一个表的总行数存在了磁盘上,因此执行count(*)的时候会直接返回这个数，效率很高 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累计计数 当然，这里说的是不加where条件的count(*)，如果加了条件，MyISAM表也不能返回这么快的。 为什么InnoDB不像MyISAM一样，也把数字存起来呢？ ​ 因为即使在同一个时刻的多个子查询，由于多版本并发控制（MVCC）的原因，而InnoDB表 应该返回多少行 也是不确定的。 比如现在某表中有1000条数据 会话A去执行select(*) 会话B开启事务，新增一条数据，再执行select * 会话A和会话B在同一时刻执行，那么他们返回的总行数是不一样的，A返回1000，而B返回1001 这和InnoDB的事务有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB会把数据一行一行的读出来依次判断，可见的行才能够计算“基于这个查询”的表的总行数 ​ MySQL在执行 count(*)操作的时候还是做了优化的。 InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是 主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树 得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑 正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一 解决方案 如果一个页面需要经常查询显示某表的总数，应该如何去做呢？ 我们应该自己去计数 用缓存系统保存计数​ 可以用Redis去记录这个表的总行数。每插入一行Redis计数就加1，每删除一行Redis计数就减1。 可能存在的问题： 1、Redis可能会丢失数据，如果我们刚在表里插入了一行数据，Redis中的值也进行了自增，然后Redis宕机了，还没来得及进行持久化，导致数据的丢失； （我们可以在Redis宕机后，手动select(*)查询总行数写回Redis) 2、Redis和MySql存在分布式事务问题； 比如某个场景下，我们需要查询显示总数，并且还要显示最近操作的100条记录。那我们就需要先从Redis里面取出计数，再去表里取数据记录 可能存在的问题，查到的100行里面没有新增的数据，但Redis的计数已经加1 另一种是，查到的100行有新增的数，但是Redis的计数还没加1 产生的原因就是，无法保证提交数据库事务的同时写入Redis， 在数据库保存计数​ 用一张表去记录总数，可以避免上述问题，因此事务的可见性，我们插入数据和修改表中记录的行数都是在方法执行完后统一提交的事务，事务还未提交时，对其他线程是不可见的 从并发系统性能的角度看，应该先插数据表，还是先更新计数表呢？ 更新计数表会涉及到行锁的竞争，先插入再更新能最大程度的减少了事务之间的锁等待，提高并发度（事务开启后，更新操作放到最后，减少锁等待时间的影响） 不同count的用法count(*)、count(id)、count(字段)、count(1)的用法的性能，有哪些差别呢。 基于InnoDB引擎 count（）是一个聚合函数，对于返回的结果集，一行一行的判断，如果count函数的参数不是null,就会累计值加1，否则不加。 所以count(*),count(id),count(字段),count(1)都返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里，参数“字段”不为null的总个数 对于count(id)来说。InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层，server层拿到id后，判断是不可能为空的，就按行累加 对于count(1)来说。InnoDB引擎遍历整张表，但是不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加 count(*)执行的要比count(id)快，因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作 对于count(字段)来说。 如果这个字段是定义为not null的话，一行行的从记录里面读取出这个字段，判断不能为null,按行累加； 如果这个字段允许为空，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加 对于count(*)来说。并不会把全部字段取出来，而是专门做了优化，不取值，count(*)肯定不是null,按行累加 按照效率排序的话，count(字段) &lt; count(id) &lt; count(1) ≈ count(*)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"Sychronized关键字-monitorenter与monitorexit","slug":"Sychronized关键字-monitorenter与monitorexit","date":"2021-12-17T11:19:25.000Z","updated":"2022-01-15T15:13:50.736Z","comments":true,"path":"2021/12/17/Sychronized关键字-monitorenter与monitorexit/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/17/Sychronized%E5%85%B3%E9%94%AE%E5%AD%97-monitorenter%E4%B8%8Emonitorexit/","excerpt":"","text":"每个对象都有一个Monitor与之关联，当Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，都可以通过成对的MonitorEnter和MonitorExit指令来实现。 12345public void method() &#123; synchronized(this) &#123; System.out.println(&quot;hello world&quot;); &#125; &#125; 经过javap解析后 1234567891011121314151617181920212223public void method(); Code: 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String hello world 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any 此处会发现有一个monitorenter，却有两个monitorexit；这是JVM的补偿机制，保证你的同步代码块中出现异常，能正常释放锁 如字节码行号4-13可能会出现异常，则会走17进行异常处理，在此处进行锁的释放","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"MySql性能调优","slug":"MySql性能调优","date":"2021-12-16T15:08:30.000Z","updated":"2021-12-17T11:47:30.089Z","comments":true,"path":"2021/12/16/MySql性能调优/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/16/MySql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","excerpt":"","text":"啥也没有，只是为了样式展示","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"gitee+hexo搭建个人博客","slug":"gitee+hexo搭建个人博客","date":"2021-12-16T12:42:22.000Z","updated":"2021-12-17T11:49:04.429Z","comments":true,"path":"2021/12/16/gitee+hexo搭建个人博客/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/16/gitee+hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"概述事前准备： 先创建一个仓库，同时在仓库根目录下创建index.html (gitee官网这样说的,没试过缺少这个文件会怎样) 安装Hexo所需环境 node.js git 自行进行下载与安装 安装1234567891011# 安装hexonpm install -g hexo# 创建文件夹,用来存储你博客内容hexo init test# cd到创建的目录,执行npm install# 开启hexo服务hexo s 访问http://localhost:4000；没有问题的话就会显示他的默认页面 修改配置关联git仓库，在你创建的目录下找到 config.yml文件（例如此处我的是test/_config.yml） 打开添加如下配置 1234deploy: type: &#x27;git&#x27; repository: https://gitee.com/xxx/xxxx # 你的仓库地址 branch: master # 你的仓库分支 生成静态页面 1hexo g #或者 hexo generate 123456# 此时若出现如下报错：ERROR Local hexo not found in ~/blogERROR Try runing: &#x27;npm install hexo --save&#x27;# 则执行命令：npm install hexo --save 将生成的页面提交到仓库 1hexo d #或者hexo deploy 若执行命令hexo deploy报错：无法连接git或找不到git，则执行如下命令来安装hexo-deployer-git： 1npm install hexo-deployer-git --save 发布文章进入到你创建的“text”目录，新建文章，执行 1hexo new &quot;blog&quot; 此时在test/source/_posts下，会新建一个名为“blog.md”的文件，利用相关markdown编辑器就能编写你的博客啦!(我这里用的typore) 123hexo g # 生成静态页面hexo d # 部署到gitee hexo有许多主题，默认生成的主题都是landscape，你也可以去主题官网寻找自己喜欢的主题 例如主题pure 1234567891011git clone https://github.com/cofess/hexo-theme-pure.git themes/pure#修改test目录下_config.yml里theme的名称,将landscape修改为pure即可 hexo clean#清除缓存文件 (db.json) 和静态文件 (public)hexo g#生成缓存和静态文件hexo d #重新部署到服务器","categories":[{"name":"others","slug":"others","permalink":"http://c89757.gitee.io/colinstar/categories/others/"}],"tags":[{"name":"others","slug":"others","permalink":"http://c89757.gitee.io/colinstar/tags/others/"}]}],"categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"},{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"},{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/categories/springboot/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://c89757.gitee.io/colinstar/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/categories/netty/"},{"name":"others","slug":"others","permalink":"http://c89757.gitee.io/colinstar/categories/others/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"},{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"},{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/tags/springboot/"},{"name":"maven","slug":"maven","permalink":"http://c89757.gitee.io/colinstar/tags/maven/"},{"name":"spring","slug":"spring","permalink":"http://c89757.gitee.io/colinstar/tags/spring/"},{"name":"堆","slug":"堆","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A0%86/"},{"name":"排序算法","slug":"排序算法","permalink":"http://c89757.gitee.io/colinstar/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"nio","slug":"nio","permalink":"http://c89757.gitee.io/colinstar/tags/nio/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/tags/netty/"},{"name":"others","slug":"others","permalink":"http://c89757.gitee.io/colinstar/tags/others/"}]}